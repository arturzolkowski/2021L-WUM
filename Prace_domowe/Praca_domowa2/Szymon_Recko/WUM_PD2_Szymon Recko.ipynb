{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "import warnings\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kodowanie zmiennych kategorycznych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wczytuję dane i zmieniam wszystkie litery na małe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allegro=pd.read_csv(\"allegro-api-transactions.csv\")\n",
    "allegro[\"it_location\"]=allegro[\"it_location\"].apply(str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TargetEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=ce.TargetEncoder()\n",
    "allegro[\"it_location_targetencoding\"]=target.fit_transform(allegro[\"it_location\"],allegro[\"price\"])\n",
    "allegro[\"it_location_targetencoding\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać dla dla każdej kateogorii została przypisana wartość liczbowa. Gdybyśmy użyli One-hot encodingu powstałyby 7903 nowe kolumny, ponieważ tyle mamy unikalnych kategorii i z tego względu Target Encoding wydaje się być lepszy. Z drugiej strony zamiana na pojedyńczą wartość numeryczną wprowadza pewnego rodzaju uporządkowanie i daje możliwość porównywania, której nie było w pierwotnych danych.\n",
    "\n",
    "TargetEncoding przypisuje każdej z kategorii, średnią wartość zmiennej objaśnianej dla tej kategorii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allegro[[\"main_category\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot=ce.OneHotEncoder()\n",
    "onehot_df=pd.read_csv(\"allegro-api-transactions.csv\")\n",
    "onehot_df=onehot_df.join(onehot.fit_transform(allegro[\"main_category\"]))\n",
    "onehot_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHotEncoding stworzył 27 nowych kolum odpowiadających 27 unikalnym kategoriom z \"main_category\". Nie mamy teraz problemu ze storzeniem sztucznego porządku podczas enncodingu dzięki czemu model nie będzie ich porównywał tak jak w przypadku gdy zastąpiliśmy kategorię jedną wartością."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OrdinalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal=ce.OrdinalEncoder()\n",
    "ordinal_df=pd.read_csv(\"allegro-api-transactions.csv\")\n",
    "ordinal_df[\"main_category_ordinal\"]=ordinal.fit_transform(allegro[\"main_category\"])\n",
    "ordinal_df[\"main_category_ordinal\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OrdinalEncoding działa na zasadzie przyporządkowania każdej kategorii losowej liczby całkowitej.Użycie tego pozostawia problem tworzenia sztucznego pożądku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HashingEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing=ce.HashingEncoder()\n",
    "hashing_df=pd.read_csv(\"allegro-api-transactions.csv\")\n",
    "hashing_df=hashing_df.join(hashing.fit_transform(allegro[\"main_category\"]))\n",
    "hashing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HashingEncoding zamienia każdą kategorię na n-wymiarowy wektor wypełniony 0 i 1. Mając kontrolę nad n możemy uniknąć robienia wielu kolum jak w onehot ale narażamy się na to, że dwie kategoie będą miały tego samego hasha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Uzupełnianie braków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11111)\n",
    "imputer=KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "allegro2=pd.read_csv(\"allegro-api-transactions.csv\")[[\"price\", \"it_seller_rating\", \"it_quantity\"]]\n",
    "allegro2=allegro2[0:42000]\n",
    "RMSE=[0 for i in range(10)]\n",
    "for i in range(10):\n",
    "    remove_index=random.sample(range(0,42000),4200)\n",
    "    allegro2_removed=allegro2.copy()\n",
    "    allegro2_removed.iloc[remove_index,1]=None\n",
    "    allegro2_imputed=pd.DataFrame(imputer.fit_transform(allegro2_removed),columns=[\"price\", \"it_seller_rating\", \"it_quantity\"])\n",
    "    RMSE[i]=mean_squared_error(allegro2[\"it_seller_rating\"],allegro2_imputed[\"it_seller_rating\"],squared=False)\n",
    "print(\"RMSE: \",RMSE)\n",
    "print(\"Std: \",np.std(RMSE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE1=[0 for i in range(10)]\n",
    "RMSE2=[0 for i in range(10)]\n",
    "for i in range(10):\n",
    "    remove_index1=random.sample(range(0,42000),4200)\n",
    "    remove_index2=random.sample(range(0,42000),4200)\n",
    "    allegro2_removed=allegro2.copy()\n",
    "    allegro2_removed.iloc[remove_index1,1]=None\n",
    "    allegro2_removed.iloc[remove_index2,2]=None\n",
    "    allegro2_imputed=pd.DataFrame(imputer.fit_transform(allegro2_removed),columns=[\"price\", \"it_seller_rating\", \"it_quantity\"])\n",
    "    RMSE1[i]=mean_squared_error(allegro2[\"it_seller_rating\"],allegro2_imputed[\"it_seller_rating\"],squared=False)\n",
    "    RMSE2[i]=mean_squared_error(allegro2[\"it_quantity\"],allegro2_imputed[\"it_quantity\"],squared=False)\n",
    "print(\"RMSE it_seller_rating: \",RMSE1)\n",
    "print(\"RMSE it_quantity: \",RMSE2)\n",
    "print(\"Std RMSE it_seller_rating: \",np.std(RMSE1))\n",
    "print(\"Std RMSE it_quantity: \",np.std(RMSE2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'RMSE it_seller_rating':RMSE+RMSE1,'iteracja':[0,1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9],'col2':[\"RMSE z jedną niepełną kolumną\" for i in range(10)]+[\"RMSE z dwoma niepełnymi kolumnami\" for i in range(10)]}\n",
    "df=pd.DataFrame(data=d)\n",
    "fig=plt.figure(figsize=(12,12))\n",
    "g=sns.barplot(x='iteracja',y='RMSE it_seller_rating',hue='col2',data=df)\n",
    "g.legend_.set_title(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z powyższego wykresu wyraźnie widać, że po usunięciu 10% wartości z innej kolumny algorytm imputacji działa zauważalnie  gorzej. Używanie automatycznego wypełniania braków np. KNNimutation wiąże się z dużym błędem oraz odchyleniem standardowym, rosnącym wraz z ilością kolumn, w których te braki występują."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
