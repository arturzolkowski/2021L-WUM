{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prognoza pogody za pomocą klasyfikacji Marcin Wilk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Wstęp do uczenia maszynowego\\\\Dane\\\\australia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.9</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>1004.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.4</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1012.9</td>\n",
       "      <td>1012.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.4</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1012.3</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.9</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>1009.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.1</td>\n",
       "      <td>35.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1010.7</td>\n",
       "      <td>1007.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.1</td>\n",
       "      <td>36.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.7</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>12.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1011.3</td>\n",
       "      <td>1009.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.1</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>13.2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1013.3</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1008.3</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.4</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.7</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>41.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>1005.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "0     17.9     35.2       0.0         12.0      12.3           48.0   \n",
       "1     18.4     28.9       0.0         14.8      13.0           37.0   \n",
       "2     19.4     37.6       0.0         10.8      10.6           46.0   \n",
       "3     21.9     38.4       0.0         11.4      12.2           31.0   \n",
       "4     24.2     41.0       0.0         11.2       8.4           35.0   \n",
       "5     27.1     36.1       0.0         13.0       0.0           43.0   \n",
       "6     23.3     34.0       0.0          9.8      12.6           41.0   \n",
       "7     16.1     34.2       0.0         14.6      13.2           37.0   \n",
       "8     19.0     35.5       0.0         12.0      12.3           48.0   \n",
       "9     19.7     35.5       0.0         11.0      12.7           41.0   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  \\\n",
       "0           6.0          20.0         20.0         13.0       1006.3   \n",
       "1          19.0          19.0         30.0          8.0       1012.9   \n",
       "2          30.0          15.0         42.0         22.0       1012.3   \n",
       "3           6.0           6.0         37.0         22.0       1012.7   \n",
       "4          17.0          13.0         19.0         15.0       1010.7   \n",
       "5           7.0          20.0         26.0         19.0       1007.7   \n",
       "6          17.0          19.0         33.0         15.0       1011.3   \n",
       "7          15.0           6.0         25.0          9.0       1013.3   \n",
       "8          30.0           9.0         46.0         28.0       1008.3   \n",
       "9          15.0          17.0         61.0         14.0       1007.9   \n",
       "\n",
       "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RainTomorrow  \n",
       "0       1004.4       2.0       5.0     26.6     33.4          0             0  \n",
       "1       1012.1       1.0       1.0     20.3     27.0          0             0  \n",
       "2       1009.2       1.0       6.0     28.7     34.9          0             0  \n",
       "3       1009.1       1.0       5.0     29.1     35.6          0             0  \n",
       "4       1007.4       1.0       6.0     33.6     37.6          0             0  \n",
       "5       1007.4       8.0       8.0     30.7     34.3          0             0  \n",
       "6       1009.9       3.0       1.0     25.0     31.5          0             0  \n",
       "7       1009.2       1.0       1.0     20.7     32.8          0             0  \n",
       "8       1004.0       1.0       5.0     23.4     33.3          0             0  \n",
       "9       1005.8       1.0       5.0     24.0     33.6          0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56420 entries, 0 to 56419\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MinTemp        56420 non-null  float64\n",
      " 1   MaxTemp        56420 non-null  float64\n",
      " 2   Rainfall       56420 non-null  float64\n",
      " 3   Evaporation    56420 non-null  float64\n",
      " 4   Sunshine       56420 non-null  float64\n",
      " 5   WindGustSpeed  56420 non-null  float64\n",
      " 6   WindSpeed9am   56420 non-null  float64\n",
      " 7   WindSpeed3pm   56420 non-null  float64\n",
      " 8   Humidity9am    56420 non-null  float64\n",
      " 9   Humidity3pm    56420 non-null  float64\n",
      " 10  Pressure9am    56420 non-null  float64\n",
      " 11  Pressure3pm    56420 non-null  float64\n",
      " 12  Cloud9am       56420 non-null  float64\n",
      " 13  Cloud3pm       56420 non-null  float64\n",
      " 14  Temp9am        56420 non-null  float64\n",
      " 15  Temp3pm        56420 non-null  float64\n",
      " 16  RainToday      56420 non-null  int64  \n",
      " 17  RainTomorrow   56420 non-null  int64  \n",
      "dtypes: float64(16), int64(2)\n",
      "memory usage: 7.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podział zbioru na testowy i treningowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W naszym zbiorze testowym znajdzie się 60% obserwacji wybranych losowo z wejściowego zbioru, natomiast pozostałe 40% trafi do zbioru treningowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.iloc[:,0:17], df[\"RainTomorrow\"], test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy jeszcze jak zbalansowane są klasy w naszym zbiorze treningowym i testowym, gdyż jest to istotne w przypadku niektórych miar skuteczności klasyfikatorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26425\n",
       "1     7427\n",
       "Name: RainTomorrow, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17568\n",
       "1     5000\n",
       "Name: RainTomorrow, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasy nie są dobrze zbalansowane, ale zmienne o wartości 1 stanowią ponad 20%. Musimy zatem uważać w przypadku niektórych miar skuteczności."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwszym modelem, który dopasujemy do tych danych będzie regresja logistyczna. Mamy tu co prawda zmienne jakościowe, ale są one już zakodowane i w dodatku mają one naturalny porządek. W tym klasyfikatorze naszym hiperparametrem będzie maksymalna liczba iteracji algorytmu szukającego parametrów naszego modelu. Ustawimy go na 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "\n",
    "lr.fit(X_train,Y_train)\n",
    "Y_hat = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y_hat</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y_test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16581</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2316</td>\n",
       "      <td>2684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y_hat       0     1\n",
       "Y_test             \n",
       "0       16581   987\n",
       "1        2316  2684"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_lr=pd.crosstab(Y_test, Y_hat, rownames = ['Y_test'], colnames = ['Y_hat'])\n",
    "table_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widzimy po tabeli incydencji nasz klasyfikator dobrze radzi sobie z obserwacjami, które powinny być zerami, lecz z kolei słabo radzi sobie z obserwacjami, które powinny należeć do klasy 1. Policzmy zatem miary dopasowania naszego klasyfikatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8774408636291475"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_lr=table_lr.iloc[0,0]/(table_lr.iloc[0,0]+table_lr.iloc[1,0])\n",
    "precision_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.943818306010929"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_lr=table_lr.iloc[0,0]/(table_lr.iloc[0,0]+table_lr.iloc[0,1])\n",
    "recall_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5368"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity_lr=table_lr.iloc[1,1]/(table_lr.iloc[1,1]+table_lr.iloc[1,0])\n",
    "specificity_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.853642325416519"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_lr=(table_lr.iloc[0,0]+table_lr.iloc[1,1])/len(Y_test)\n",
    "accuracy_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomimo tego, że accuracy, recall i precision są wysokie, nie jest to raczej klasyfikator, którego chcielibyśmy używać. Ich wysokie wartości wynikają raczej z niezbalansowania klas w zbiorze testowym. Dobrą miarą dopasowania jest tutaj specifity, która wynosi lekko ponad 0.5. Oznacza, to że przewidzimy tylko połowę dni deszczowych, całą resztę klasyfikując jako te bez deszczu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiwny Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drugim klasyfikatorem, którego użyjemy do naszego zbioru jest naiwny klasyfikator bayesowski. Jest on oparty na założeniach normalności zmiennych ciągłych i niezależności wszystkich zmiennych objaśniających, jednak intuicyjnie czujemy, że niektóre z naszych zmiennych jak temperatury o 9 i 15 będą jak najbardziej zależne. Będziemy więc nieco sceptyczni co do tego modelu, ale może okaże się, że zadziała dobrze. Hiperparametrem będzie var_smoothing czyli jaką część największej wariancji spośród wszystkich zmiennych mamy dodać do pozostałych wariancji, które bedziemy estymować w celu znalezienia parametrów rozkładu normalnego dla zmiennych ciągłych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB(var_smoothing=1e-10)\n",
    "nb.fit(X_train,Y_train)\n",
    "Y_hat = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y_hat</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y_test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14695</td>\n",
       "      <td>2873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1546</td>\n",
       "      <td>3454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y_hat       0     1\n",
       "Y_test             \n",
       "0       14695  2873\n",
       "1        1546  3454"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_nb=pd.crosstab(Y_test, Y_hat, rownames = ['Y_test'], colnames = ['Y_hat'])\n",
    "table_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabela incydencji zdecydowanie różni się od regresji logistycznej. Widzimy, że w tym przypadku gorzej klasyfikuje nam dni bezdeszczowe, jednak klasyfikuje znacznie mniej dni deszczowych jako bezdeszczowe. Sprawdźmy jak wyglądają miary jakości tego klasyfikatora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9048088171910597"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_nb=table_nb.iloc[0,0]/(table_nb.iloc[0,0]+table_nb.iloc[1,0])\n",
    "precision_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8364640255009107"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_nb=table_nb.iloc[0,0]/(table_nb.iloc[0,0]+table_nb.iloc[0,1])\n",
    "recall_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6908"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity_nb=table_nb.iloc[1,1]/(table_nb.iloc[1,1]+table_nb.iloc[1,0])\n",
    "specificity_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8041917759659695"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_nb=(table_nb.iloc[0,0]+table_nb.iloc[1,1])/len(Y_test)\n",
    "accuracy_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie miary są w miarę wysokie, możemy zatem wnioskować, że brak zbalansowania klas nie miał zbytniego wpływu na nasz klasyfikator. Model ten nie wydaje się również przeuczony."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drzewo decyzyjne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatnim klasyfikatorem, który wytestujemy bedzie drzewo decyzyjne. Powinno ono dobrze poradzić sobie ze zmiennymi jakościowymi, które są uporządkowane, jak również oczywiście ze zmiennymi binarnymi i ciągłymi. Hiperparametrami, który tutaj ustawimy bedą maksymalna liczba obserwacji w węźle przy której dalej będziemy dokonywać podziału, czyli *min_samples_split*, *max_depth* - maksymalna głębokość drzewa oraz *criterion* czyli miara, przy pomocy której będziemy wybierać zmienne i metody podziału w węzłach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "dt = DecisionTreeClassifier(min_samples_split=20,max_depth=5,criterion=\"entropy\")\n",
    "dt.fit(X_train,Y_train)\n",
    "Y_hat = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y_hat</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y_test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16559</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2544</td>\n",
       "      <td>2456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y_hat       0     1\n",
       "Y_test             \n",
       "0       16559  1009\n",
       "1        2544  2456"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_dt=pd.crosstab(Y_test, Y_hat, rownames = ['Y_test'], colnames = ['Y_hat'])\n",
    "table_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabela incydencji przypomina nieco regresję logistyczną, choć jest nawet minimalnie gorsza. Powinna nam to również potwierdzić specifity, ale zobaczmy też inne miary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668271999162436"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_dt=table_dt.iloc[0,0]/(table_dt.iloc[0,0]+table_dt.iloc[1,0])\n",
    "precision_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.942566029143898"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_dt=table_dt.iloc[0,0]/(table_dt.iloc[0,0]+table_dt.iloc[0,1])\n",
    "recall_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4912"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity_dt=table_dt.iloc[1,1]/(table_dt.iloc[1,1]+table_dt.iloc[1,0])\n",
    "specificity_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842564693371145"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dt=(table_dt.iloc[0,0]+table_dt.iloc[1,1])/len(Y_test)\n",
    "accuracy_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomimo wysokich precision, recall i accuracy mamy raczej niską specificity, wynoszącą mniej niż 50%. Oznacza, to że nie przewidzymy ponad połowy deszczowych dni, co zdecydowanie nas nie zadowala. Pozostałe miary są wysokie najprawdopodobniej z powodu niezbalansowania klas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wnioski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomimo tego, że założenia naiwnego Bayesa raczej nie były w większości spełnione, model ten okazał się dla mnie najlepszy. Nie miał co prawda wszystkich miar najlepszych spośród tych 3 modeli, ale wyglądał na najmniej przeuczony i najmniej wrażliwy na brak balansu w klasach. Zaletą tego modelu było jednak to, że zapewne w przeciweństwie do regresji logistycznej lepiej poradził sobie ze zmiennymi jakościowymi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele regresji logistycznej i drzewa decyzyjnego raczej słabo poradziły sobie z klasyfikacją, miały niską specifity, na poziomie 0.5. Możliwe, że regresja logistyczna mogłaby sobie lepiej poradzić nawet bez zmiennych jakościowych. Po drzewie spodziewałem się trochę więcej, powinno ono poradzić sobie dobrze ze wszystkimi zmiennymi. Miało ono jednak wiele hiperparametrów, które możnaby było lepiej nastroić, więc przy tak dobranych przeze mnie może byc po prostu przeuczone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
