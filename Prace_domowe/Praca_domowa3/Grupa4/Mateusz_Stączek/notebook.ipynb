{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python364jvsc74a57bd004606736835ced50b2f8ceb4af3b6d2f2d9f63fb25a08ee510cb5a301b486e40",
   "display_name": "Python 3.6.4 64-bit ('machine_learning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# HW3\n",
    " by Mateusz StÄ…czek"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dalex import Explainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"australia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 56420 entries, 0 to 56419\nData columns (total 18 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   MinTemp        56420 non-null  float64\n 1   MaxTemp        56420 non-null  float64\n 2   Rainfall       56420 non-null  float64\n 3   Evaporation    56420 non-null  float64\n 4   Sunshine       56420 non-null  float64\n 5   WindGustSpeed  56420 non-null  float64\n 6   WindSpeed9am   56420 non-null  float64\n 7   WindSpeed3pm   56420 non-null  float64\n 8   Humidity9am    56420 non-null  float64\n 9   Humidity3pm    56420 non-null  float64\n 10  Pressure9am    56420 non-null  float64\n 11  Pressure3pm    56420 non-null  float64\n 12  Cloud9am       56420 non-null  float64\n 13  Cloud3pm       56420 non-null  float64\n 14  Temp9am        56420 non-null  float64\n 15  Temp3pm        56420 non-null  float64\n 16  RainToday      56420 non-null  int64  \n 17  RainTomorrow   56420 non-null  int64  \ndtypes: float64(16), int64(2)\nmemory usage: 7.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "No nulls detected, all features are numerical (as stated in homework desciption)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    43993\n",
       "1    12427\n",
       "Name: RainTomorrow, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.RainTomorrow.value_counts()"
   ]
  },
  {
   "source": [
    "## Splitting data on test and train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"RainTomorrow\"])\n",
    "y = df.RainTomorrow\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=3)"
   ]
  },
  {
   "source": [
    "Most records have target value $0$, which may cause lower scores in some cases in some classifiers... Let's create 3 classifiers.\n",
    "\n",
    "## Creating and fitting 3 models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression parameters: max iterations 100 -> 1000, tolerance for stopping criteria 1e-4 -> 1e-5\n",
    "lr_model = LogisticRegression(max_iter=1000, tol=0.00001, n_jobs=-1,random_state=3)\n",
    "# KNeighbors parameters: n_neighbors 5 -> 8, algorithm auto -> brute\n",
    "knc_model = KNeighborsClassifier(n_neighbors=8,algorithm='brute', n_jobs=-1)\n",
    "# LGBM parameters: num_leaves 31 -> 10, n_estimators 100 -> 1000\n",
    "lgbm_model = LGBMClassifier(num_leaves=10,n_estimators=1000, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitmodel(model):\n",
    "    return model.fit(X_train, y_train)\n",
    "\n",
    "lr_model = fitmodel(lr_model)\n",
    "knc_model = fitmodel(knc_model)\n",
    "lgbm_model = fitmodel(lgbm_model)"
   ]
  },
  {
   "source": [
    "## Comparing classifiers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        recall  precision        f1  accuracy       auc\n",
       "LogisticRegression    0.528594   0.721018  0.609991  0.849167  0.873780\n",
       "KNeighborsClassifier  0.566720   0.671214  0.614556  0.841368  0.846966\n",
       "LGBMClassifier        0.556394   0.733124  0.632648  0.855814  0.891601"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.528594</td>\n      <td>0.721018</td>\n      <td>0.609991</td>\n      <td>0.849167</td>\n      <td>0.873780</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <td>0.566720</td>\n      <td>0.671214</td>\n      <td>0.614556</td>\n      <td>0.841368</td>\n      <td>0.846966</td>\n    </tr>\n    <tr>\n      <th>LGBMClassifier</th>\n      <td>0.556394</td>\n      <td>0.733124</td>\n      <td>0.632648</td>\n      <td>0.855814</td>\n      <td>0.891601</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "def compare_models(models: list, X, y):\n",
    "    def get_scores(model):\n",
    "        return Explainer(model, X, y, verbose=False).model_performance().result\n",
    "    return pd.concat([get_scores(model) for model in models])\n",
    "    \n",
    "compare_models([lr_model, knc_model, lgbm_model], X_test, y_test)"
   ]
  },
  {
   "source": [
    "Are the models visibly overfitted?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        recall  precision        f1  accuracy       auc\n",
       "LogisticRegression    0.529720   0.728927  0.613559  0.853509  0.882737\n",
       "KNeighborsClassifier  0.646483   0.746272  0.692803  0.874136  0.926644\n",
       "LGBMClassifier        0.682309   0.869247  0.764516  0.907723  0.957494"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recall</th>\n      <th>precision</th>\n      <th>f1</th>\n      <th>accuracy</th>\n      <th>auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.529720</td>\n      <td>0.728927</td>\n      <td>0.613559</td>\n      <td>0.853509</td>\n      <td>0.882737</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <td>0.646483</td>\n      <td>0.746272</td>\n      <td>0.692803</td>\n      <td>0.874136</td>\n      <td>0.926644</td>\n    </tr>\n    <tr>\n      <th>LGBMClassifier</th>\n      <td>0.682309</td>\n      <td>0.869247</td>\n      <td>0.764516</td>\n      <td>0.907723</td>\n      <td>0.957494</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "compare_models([lr_model, knc_model, lgbm_model], X_train, y_train)"
   ]
  },
  {
   "source": [
    "LBGM might be a bit overfitted but overall everything is looking fine. \n",
    "\n",
    "## Summary\n",
    "\n",
    "Given unbalanced data, model with the highest f1 score is LGBM Classifier.\n",
    "\n",
    "Fine-tuning hyperparameters would probably yield better scores for every model but this task is beyond this homework.\n",
    "\n",
    "Overall, no model can be chosen as \"better\" than others since all have very similar scores."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}