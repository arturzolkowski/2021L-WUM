{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E14kt20mt7VI"
   },
   "source": [
    "# Inżynieria cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0gMSSznrDItQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from category_encoders import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQCWmESNtzNd"
   },
   "source": [
    "# Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "y3Ov4sQBtkZ0",
    "outputId": "712a0a77-ba04-4a9c-b87b-2e7384bfbf5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        4   0  11  11  \n",
       "1      5        3      3     1     1      3        2   9  11  11  \n",
       "2      4        3      2     2     3      3        6  12  13  12  \n",
       "3      3        2      2     1     1      5        0  14  14  14  \n",
       "4      4        3      2     1     2      5        0  11  13  13  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_df=pd.read_csv('https://lovespreadsheet-tutorials.s3.amazonaws.com/APIDatasets/school_grades_dataset.csv')\n",
    "grades_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "rFaCOuCMyD47",
    "outputId": "f0573d93-9490-4c43-f050-1508460e594e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>MS</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>MS</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>R</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "644     MS   F   19       R     GT3       T     2     3  services     other   \n",
       "645     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
       "646     MS   F   18       U     GT3       T     1     1     other     other   \n",
       "647     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "648     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "\n",
       "     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0    ...      4        3      4     1     1      3        4   0  11  11  \n",
       "1    ...      5        3      3     1     1      3        2   9  11  11  \n",
       "2    ...      4        3      2     2     3      3        6  12  13  12  \n",
       "3    ...      3        2      2     1     1      5        0  14  14  14  \n",
       "4    ...      4        3      2     1     2      5        0  11  13  13  \n",
       "..   ...    ...      ...    ...   ...   ...    ...      ...  ..  ..  ..  \n",
       "644  ...      5        4      2     1     2      5        4  10  11  10  \n",
       "645  ...      4        3      4     1     1      1        4  15  15  16  \n",
       "646  ...      1        1      1     1     1      5        6  11  12   9  \n",
       "647  ...      2        4      5     3     4      2        6  10  10  10  \n",
       "648  ...      4        4      1     3     4      5        4  10  11  11  \n",
       "\n",
       "[649 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_changed=grades_df.copy()\n",
    "grades_changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać wiele kolumn zawiera wartości inne niż takie będące liczbowymi. Stąd by przeprowadzić lepsze modelowanie, postanowiliśmy zamienić je na wartości numeryczne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>...</th>\n",
       "      <th>Fjob_other</th>\n",
       "      <th>Fjob_services</th>\n",
       "      <th>Fjob_teacher</th>\n",
       "      <th>guardian_father</th>\n",
       "      <th>guardian_mother</th>\n",
       "      <th>guardian_other</th>\n",
       "      <th>reason_course</th>\n",
       "      <th>reason_home</th>\n",
       "      <th>reason_other</th>\n",
       "      <th>reason_reputation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  \\\n",
       "0     18     4     4           2          2         0       4         3   \n",
       "1     17     1     1           1          2         0       5         3   \n",
       "2     15     1     1           1          2         0       4         3   \n",
       "3     15     4     2           1          3         0       3         2   \n",
       "4     16     3     3           1          2         0       4         3   \n",
       "..   ...   ...   ...         ...        ...       ...     ...       ...   \n",
       "644   19     2     3           1          3         1       5         4   \n",
       "645   18     3     1           1          2         0       4         3   \n",
       "646   18     1     1           2          2         0       1         1   \n",
       "647   17     3     1           2          1         0       2         4   \n",
       "648   18     3     2           3          1         0       4         4   \n",
       "\n",
       "     goout  Dalc  ...  Fjob_other  Fjob_services  Fjob_teacher  \\\n",
       "0        4     1  ...           0              0             1   \n",
       "1        3     1  ...           1              0             0   \n",
       "2        2     2  ...           1              0             0   \n",
       "3        2     1  ...           0              1             0   \n",
       "4        2     1  ...           1              0             0   \n",
       "..     ...   ...  ...         ...            ...           ...   \n",
       "644      2     1  ...           1              0             0   \n",
       "645      4     1  ...           0              1             0   \n",
       "646      1     1  ...           1              0             0   \n",
       "647      5     3  ...           0              1             0   \n",
       "648      1     3  ...           1              0             0   \n",
       "\n",
       "     guardian_father  guardian_mother  guardian_other  reason_course  \\\n",
       "0                  0                1               0              1   \n",
       "1                  1                0               0              1   \n",
       "2                  0                1               0              0   \n",
       "3                  0                1               0              0   \n",
       "4                  1                0               0              0   \n",
       "..               ...              ...             ...            ...   \n",
       "644                0                1               0              1   \n",
       "645                0                1               0              1   \n",
       "646                0                1               0              1   \n",
       "647                0                1               0              1   \n",
       "648                0                1               0              1   \n",
       "\n",
       "     reason_home  reason_other  reason_reputation  \n",
       "0              0             0                  0  \n",
       "1              0             0                  0  \n",
       "2              0             1                  0  \n",
       "3              1             0                  0  \n",
       "4              1             0                  0  \n",
       "..           ...           ...                ...  \n",
       "644            0             0                  0  \n",
       "645            0             0                  0  \n",
       "646            0             0                  0  \n",
       "647            0             0                  0  \n",
       "648            0             0                  0  \n",
       "\n",
       "[649 rows x 46 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = grades_df.select_dtypes(include=np.object).columns.tolist()\n",
    "categorical_multi = ['Mjob', 'Fjob', 'guardian', 'reason']\n",
    "categorical.remove('Mjob')\n",
    "categorical.remove('Fjob')\n",
    "categorical.remove('guardian')\n",
    "categorical.remove('reason')\n",
    "\n",
    "grades_changed = pd.get_dummies(grades_changed, columns=categorical, drop_first=True)\n",
    "grades_changed = pd.get_dummies(grades_changed, columns=categorical_multi)\n",
    "grades_changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W naszych danych podano wyniki śródsemestralnych egzaminów dla poszczególnych studentów (\"G1\", \"G2\"), które są bardzo zbliżone do wyników ostatecznych (\"G3\"). Stąd zdecydowaliśmy się przygotować modele na dwóch rodzajach danych - tych zawierających kolumny \"G1\" oraz \"G2\" oraz takich, które ich nie zawierają."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iEOJKlB34cXA"
   },
   "outputs": [],
   "source": [
    "X_without_exams = grades_changed.drop([\"G1\", \"G2\", \"G3\"], axis=1)\n",
    "X_with_exams = grades_changed.drop(\"G3\", axis=1)\n",
    "Y = grades_changed.G3\n",
    "total_results_with = pd.DataFrame(columns=[\"Model\", \"RMSE\"])\n",
    "total_results_without = pd.DataFrame(columns=[\"Model\", \"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, max_error, make_scorer\n",
    "\n",
    "def append_to_results(df, model, scores):\n",
    "    return df.append(pd.DataFrame({\n",
    "        \"Model\": np.repeat(model, scores.size),\n",
    "        \"RMSE\": scores}))\n",
    "\n",
    "def avg_sd_print(data):\n",
    "    print(f\"Average: {np.mean(data):.3f}\\nStandard deviation: {np.std(data):.3f}\")\n",
    "    \n",
    "    \n",
    "metrics = {\"rmse\": make_scorer(mean_squared_error, squared=False)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele klasyfikacyjne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drzewo decyzyjne\n",
    "### Z egzaminami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.565333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.565333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.565333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.579300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.579300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.579300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.633985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.655399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.668336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.672512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.675449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.697176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.811785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.825418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.835029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.865531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.922309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.927519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.927519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.927519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.927686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.976588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.981312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.982996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.982996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.982996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.055008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.080091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_criterion param_max_depth param_min_samples_split param_random_state  \\\n",
       "19         entropy               4                       6                  1   \n",
       "18         entropy               4                       2                  1   \n",
       "20         entropy               4                      10                  1   \n",
       "3             gini               4                       2                  1   \n",
       "4             gini               4                       6                  1   \n",
       "5             gini               4                      10                  1   \n",
       "22         entropy               6                       6                  1   \n",
       "23         entropy               6                      10                  1   \n",
       "29         entropy              10                      10                  1   \n",
       "26         entropy               8                      10                  1   \n",
       "25         entropy               8                       6                  1   \n",
       "28         entropy              10                       6                  1   \n",
       "21         entropy               6                       2                  1   \n",
       "7             gini               6                       6                  1   \n",
       "27         entropy              10                       2                  1   \n",
       "24         entropy               8                       2                  1   \n",
       "8             gini               6                      10                  1   \n",
       "6             gini               6                       2                  1   \n",
       "11            gini               8                      10                  1   \n",
       "15         entropy               2                       2                  1   \n",
       "16         entropy               2                       6                  1   \n",
       "17         entropy               2                      10                  1   \n",
       "14            gini              10                      10                  1   \n",
       "12            gini              10                       2                  1   \n",
       "10            gini               8                       6                  1   \n",
       "2             gini               2                      10                  1   \n",
       "1             gini               2                       6                  1   \n",
       "0             gini               2                       2                  1   \n",
       "13            gini              10                       6                  1   \n",
       "9             gini               8                       2                  1   \n",
       "\n",
       "    mean_test_rmse  \n",
       "19        1.565333  \n",
       "18        1.565333  \n",
       "20        1.565333  \n",
       "3         1.579300  \n",
       "4         1.579300  \n",
       "5         1.579300  \n",
       "22        1.633985  \n",
       "23        1.655399  \n",
       "29        1.668336  \n",
       "26        1.672512  \n",
       "25        1.675449  \n",
       "28        1.677250  \n",
       "21        1.697176  \n",
       "7         1.811785  \n",
       "27        1.825418  \n",
       "24        1.835029  \n",
       "8         1.864532  \n",
       "6         1.865531  \n",
       "11        1.922309  \n",
       "15        1.927519  \n",
       "16        1.927519  \n",
       "17        1.927519  \n",
       "14        1.927686  \n",
       "12        1.976588  \n",
       "10        1.981312  \n",
       "2         1.982996  \n",
       "1         1.982996  \n",
       "0         1.982996  \n",
       "13        2.055008  \n",
       "9         2.080091  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "\n",
    "simple_tree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "             \"max_depth\": [2, 4, 6, 8, 10],\n",
    "             \"min_samples_split\": [2, 6, 10],\n",
    "             \"random_state\": [1]}\n",
    "\n",
    "tree_grid = GridSearchCV(simple_tree, scoring=metrics, param_grid=parameters, refit=\"rmse\", cv=5)\n",
    "tree_grid.fit(X_with_exams, Y)\n",
    "grid = pd.DataFrame(tree_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with exams\n",
      "Average: 1.565\n",
      "Standard deviation: 0.240\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 4, min_samples_split = 6, random_state = 1)\n",
    "\n",
    "result_with = cross_validate(tree, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "total_results_with = append_to_results(total_results_with, \"Decision Tree\", result_with.get('test_rmse'))\n",
    "\n",
    "print(\"Decision Tree with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bez egzaminów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.336951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.336951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.336951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.474029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.607393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.610353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.791909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.795743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.852419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.892847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.893045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.902702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.918625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.960242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.973328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.026929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4.065750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.065750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.079169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.103116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.103515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4.122057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4.177408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.277432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.278797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4.278797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.450453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4.450453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.450453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_criterion param_max_depth param_min_samples_split param_random_state  \\\n",
       "0             gini               2                       2                  1   \n",
       "1             gini               2                       6                  1   \n",
       "2             gini               2                      10                  1   \n",
       "6             gini               6                       2                  1   \n",
       "8             gini               6                      10                  1   \n",
       "7             gini               6                       6                  1   \n",
       "26         entropy               8                      10                  1   \n",
       "29         entropy              10                      10                  1   \n",
       "24         entropy               8                       2                  1   \n",
       "11            gini               8                      10                  1   \n",
       "23         entropy               6                      10                  1   \n",
       "21         entropy               6                       2                  1   \n",
       "14            gini              10                      10                  1   \n",
       "25         entropy               8                       6                  1   \n",
       "28         entropy              10                       6                  1   \n",
       "22         entropy               6                       6                  1   \n",
       "27         entropy              10                       2                  1   \n",
       "19         entropy               4                       6                  1   \n",
       "18         entropy               4                       2                  1   \n",
       "9             gini               8                       2                  1   \n",
       "20         entropy               4                      10                  1   \n",
       "12            gini              10                       2                  1   \n",
       "13            gini              10                       6                  1   \n",
       "10            gini               8                       6                  1   \n",
       "5             gini               4                      10                  1   \n",
       "3             gini               4                       2                  1   \n",
       "4             gini               4                       6                  1   \n",
       "17         entropy               2                      10                  1   \n",
       "16         entropy               2                       6                  1   \n",
       "15         entropy               2                       2                  1   \n",
       "\n",
       "    mean_test_rmse  \n",
       "0         3.336951  \n",
       "1         3.336951  \n",
       "2         3.336951  \n",
       "6         3.474029  \n",
       "8         3.607393  \n",
       "7         3.610353  \n",
       "26        3.791909  \n",
       "29        3.795743  \n",
       "24        3.852419  \n",
       "11        3.892847  \n",
       "23        3.893045  \n",
       "21        3.902702  \n",
       "14        3.912064  \n",
       "25        3.918625  \n",
       "28        3.960242  \n",
       "22        3.973328  \n",
       "27        4.026929  \n",
       "19        4.065750  \n",
       "18        4.065750  \n",
       "9         4.079169  \n",
       "20        4.103116  \n",
       "12        4.103515  \n",
       "13        4.122057  \n",
       "10        4.177408  \n",
       "5         4.277432  \n",
       "3         4.278797  \n",
       "4         4.278797  \n",
       "17        4.450453  \n",
       "16        4.450453  \n",
       "15        4.450453  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "\n",
    "simple_tree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "             \"max_depth\": [2, 4, 6, 8, 10],\n",
    "             \"min_samples_split\": [2, 6, 10],\n",
    "             \"random_state\": [1]}\n",
    "\n",
    "tree_grid = GridSearchCV(simple_tree, scoring=metrics, param_grid=parameters, refit=\"rmse\", cv=5)\n",
    "tree_grid.fit(X_without_exams, Y)\n",
    "grid = pd.DataFrame(tree_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree without exams\n",
      "Average: 3.337\n",
      "Standard deviation: 0.329\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion = \"gini\", max_depth = 2, min_samples_split = 2, random_state = 1)\n",
    "\n",
    "result_without = cross_validate(tree, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "total_results_without = append_to_results(total_results_without, \"Decision Tree\", result_without.get('test_rmse'))\n",
    "\n",
    "print(\"Decision Tree without exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las losowy\n",
    "### Z egzaminami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.618472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.651204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.670074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.692665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.700262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.710207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.735646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.755697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.813191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.840893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.842453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.843321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.843399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.853146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.861642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.880488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.886707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.023041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.116478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.119090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.148774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.157173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.158402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.182996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.456623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.456623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.456623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.484876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.484876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.484876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_criterion param_max_depth param_min_samples_split param_random_state  \\\n",
       "25         entropy               8                       6                  1   \n",
       "28         entropy              10                       6                  1   \n",
       "24         entropy               8                       2                  1   \n",
       "27         entropy              10                       2                  1   \n",
       "9             gini               8                       2                  1   \n",
       "13            gini              10                       6                  1   \n",
       "29         entropy              10                      10                  1   \n",
       "12            gini              10                       2                  1   \n",
       "22         entropy               6                       6                  1   \n",
       "26         entropy               8                      10                  1   \n",
       "14            gini              10                      10                  1   \n",
       "10            gini               8                       6                  1   \n",
       "11            gini               8                      10                  1   \n",
       "6             gini               6                       2                  1   \n",
       "23         entropy               6                      10                  1   \n",
       "21         entropy               6                       2                  1   \n",
       "8             gini               6                      10                  1   \n",
       "7             gini               6                       6                  1   \n",
       "19         entropy               4                       6                  1   \n",
       "20         entropy               4                      10                  1   \n",
       "3             gini               4                       2                  1   \n",
       "4             gini               4                       6                  1   \n",
       "18         entropy               4                       2                  1   \n",
       "5             gini               4                      10                  1   \n",
       "17         entropy               2                      10                  1   \n",
       "16         entropy               2                       6                  1   \n",
       "15         entropy               2                       2                  1   \n",
       "2             gini               2                      10                  1   \n",
       "1             gini               2                       6                  1   \n",
       "0             gini               2                       2                  1   \n",
       "\n",
       "    mean_test_rmse  \n",
       "25        1.618472  \n",
       "28        1.651204  \n",
       "24        1.670074  \n",
       "27        1.692665  \n",
       "9         1.700262  \n",
       "13        1.710207  \n",
       "29        1.735646  \n",
       "12        1.755697  \n",
       "22        1.813191  \n",
       "26        1.840893  \n",
       "14        1.842453  \n",
       "10        1.843321  \n",
       "11        1.843399  \n",
       "6         1.853146  \n",
       "23        1.861642  \n",
       "21        1.880488  \n",
       "8         1.886707  \n",
       "7         2.023041  \n",
       "19        2.116478  \n",
       "20        2.119090  \n",
       "3         2.148774  \n",
       "4         2.157173  \n",
       "18        2.158402  \n",
       "5         2.182996  \n",
       "17        2.456623  \n",
       "16        2.456623  \n",
       "15        2.456623  \n",
       "2         2.484876  \n",
       "1         2.484876  \n",
       "0         2.484876  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "parameters = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "             \"max_depth\": [2, 4, 6, 8, 10],\n",
    "             \"min_samples_split\": [2, 6, 10],\n",
    "             \"random_state\": [1]}\n",
    "\n",
    "rf_grid = GridSearchCV(rf, scoring=metrics, param_grid=parameters, refit=\"rmse\", cv=5)\n",
    "rf_grid.fit(X_with_exams, Y)\n",
    "grid = pd.DataFrame(rf_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with exams\n",
      "Average: 1.618\n",
      "Standard deviation: 0.369\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(criterion = \"entropy\", max_depth = 8, min_samples_split = 6, random_state = 1)\n",
    "\n",
    "result_with = cross_validate(rf, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "total_results_with = append_to_results(total_results_with, \"Random Forest\", result_with.get('test_rmse'))\n",
    "\n",
    "print(\"Random Forest with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bez egzaminów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.059361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.079901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.090344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.098467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.105158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.107992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.113843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.124395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.127446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.139060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.154397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.155666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.155957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.156568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.156822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.164910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.187883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.191052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.195731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.195731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.195731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.207044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.207044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3.207044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.212105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.232652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.238932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.297883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.338956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.352046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_criterion param_max_depth param_min_samples_split param_random_state  \\\n",
       "23         entropy               6                      10                  1   \n",
       "22         entropy               6                       6                  1   \n",
       "19         entropy               4                       6                  1   \n",
       "18         entropy               4                       2                  1   \n",
       "20         entropy               4                      10                  1   \n",
       "3             gini               4                       2                  1   \n",
       "6             gini               6                       2                  1   \n",
       "5             gini               4                      10                  1   \n",
       "8             gini               6                      10                  1   \n",
       "4             gini               4                       6                  1   \n",
       "14            gini              10                      10                  1   \n",
       "28         entropy              10                       6                  1   \n",
       "29         entropy              10                      10                  1   \n",
       "26         entropy               8                      10                  1   \n",
       "7             gini               6                       6                  1   \n",
       "10            gini               8                       6                  1   \n",
       "25         entropy               8                       6                  1   \n",
       "11            gini               8                      10                  1   \n",
       "0             gini               2                       2                  1   \n",
       "2             gini               2                      10                  1   \n",
       "1             gini               2                       6                  1   \n",
       "15         entropy               2                       2                  1   \n",
       "16         entropy               2                       6                  1   \n",
       "17         entropy               2                      10                  1   \n",
       "13            gini              10                       6                  1   \n",
       "21         entropy               6                       2                  1   \n",
       "9             gini               8                       2                  1   \n",
       "27         entropy              10                       2                  1   \n",
       "24         entropy               8                       2                  1   \n",
       "12            gini              10                       2                  1   \n",
       "\n",
       "    mean_test_rmse  \n",
       "23        3.059361  \n",
       "22        3.079901  \n",
       "19        3.090344  \n",
       "18        3.098467  \n",
       "20        3.105158  \n",
       "3         3.107992  \n",
       "6         3.113843  \n",
       "5         3.124395  \n",
       "8         3.127446  \n",
       "4         3.139060  \n",
       "14        3.154397  \n",
       "28        3.155666  \n",
       "29        3.155957  \n",
       "26        3.156568  \n",
       "7         3.156822  \n",
       "10        3.164910  \n",
       "25        3.187883  \n",
       "11        3.191052  \n",
       "0         3.195731  \n",
       "2         3.195731  \n",
       "1         3.195731  \n",
       "15        3.207044  \n",
       "16        3.207044  \n",
       "17        3.207044  \n",
       "13        3.212105  \n",
       "21        3.232652  \n",
       "9         3.238932  \n",
       "27        3.297883  \n",
       "24        3.338956  \n",
       "12        3.352046  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "parameters = {\"criterion\": [\"gini\", \"entropy\"],\n",
    "             \"max_depth\": [2, 4, 6, 8, 10],\n",
    "             \"min_samples_split\": [2, 6, 10],\n",
    "             \"random_state\": [1]}\n",
    "\n",
    "rf_grid = GridSearchCV(rf, scoring=metrics, param_grid=parameters, refit=\"rmse\", cv=5)\n",
    "rf_grid.fit(X_without_exams, Y)\n",
    "grid = pd.DataFrame(rf_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest without exams\n",
      "Average: 3.059\n",
      "Standard deviation: 0.290\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(criterion = \"entropy\", max_depth = 6, min_samples_split = 10, random_state = 1)\n",
    "\n",
    "result_without = cross_validate(rf, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "total_results_without = append_to_results(total_results_without, \"Random Forest\", result_without.get('test_rmse'))\n",
    "\n",
    "print(\"Random Forest without exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co ciekawe, predykcja Random Forest była nieco gorsza niż dla pojedynczego Decision Tree w przypadku danych z egzaminami. Dla danych bez wyników egzaminów Random Forest okazał się jednak dużo lepszy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "### Z egzaminami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.461080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1.465380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.473058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.514126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.515980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.522031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.526778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.531580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.538470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.543017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.543746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.543746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_subsample  mean_test_rmse\n",
       "9               14               1        1.461080\n",
       "11              18               1        1.465380\n",
       "7               11               1        1.473058\n",
       "5                9               1        1.514126\n",
       "3                7               1        1.515980\n",
       "2                7             0.8        1.522031\n",
       "0                5             0.8        1.526778\n",
       "1                5               1        1.531580\n",
       "6               11             0.8        1.538470\n",
       "4                9             0.8        1.543017\n",
       "8               14             0.8        1.543746\n",
       "10              18             0.8        1.543746"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(booster='gbtree', eval_metric='mlogloss')\n",
    "parameters = {\"max_depth\": [5, 7, 9, 11, 14, 18],\n",
    "             \"subsample\": [0.8, 1]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb, scoring=metrics, param_grid=parameters, refit=\"rmse\", cv=5)\n",
    "xgb_grid.fit(X_with_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(xgb_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najepszy model z egzaminami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost with exams\n",
      "Average: 1.461\n",
      "Standard deviation: 0.282\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(booster='gbtree', eval_metric='mlogloss', max_depth=14, subsample=1)\n",
    "\n",
    "result_with = cross_validate(xgb, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "total_results_with = append_to_results(total_results_with, \"XGBoost Classifier\", result_with.get('test_rmse'))\n",
    "\n",
    "print(\"XGBoost with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bez egzaminów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.400549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.431667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.447907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.524696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.536507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.559737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.568478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.572791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.601696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.630078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.644960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.645686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.647077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.677943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.702903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.727746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.729229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3.814353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.842220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.870406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3.880865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_subsample  mean_test_rmse\n",
       "6                3             0.6        3.400549\n",
       "7                3             0.8        3.431667\n",
       "4                2             0.8        3.447907\n",
       "3                2             0.6        3.524696\n",
       "9                5             0.6        3.536507\n",
       "12               7             0.6        3.559737\n",
       "1                1             0.8        3.568478\n",
       "0                1             0.6        3.572791\n",
       "5                2               1        3.601696\n",
       "2                1               1        3.630078\n",
       "10               5             0.8        3.644960\n",
       "16               9             0.8        3.645686\n",
       "8                3               1        3.647077\n",
       "15               9             0.6        3.677943\n",
       "18              11             0.6        3.702903\n",
       "19              11             0.8        3.727746\n",
       "11               5               1        3.729229\n",
       "14               7               1        3.814353\n",
       "13               7             0.8        3.842220\n",
       "20              11               1        3.870406\n",
       "17               9               1        3.880865"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(booster='gbtree', eval_metric='mlogloss')\n",
    "parameters = {\"max_depth\": [1, 2, 3, 5, 7, 9, 11],\n",
    "             \"subsample\": [0.6, 0.8, 1]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb, scoring=metrics, param_grid=parameters, refit=\"rmse\", cv=5)\n",
    "xgb_grid.fit(X_without_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(xgb_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost without exams\n",
      "Average: 3.401\n",
      "Standard deviation: 0.655\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(booster='gbtree', eval_metric='mlogloss', max_depth=3, subsample=0.6)\n",
    "\n",
    "result_without = cross_validate(xgb, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "total_results_without = append_to_results(total_results_without, \"XGBoost Classifier\", result_without.get('test_rmse'))\n",
    "\n",
    "print(\"XGBoost without exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modele regresji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(x):\n",
    "    return np.rint(x).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBbM2IlG1Ygb"
   },
   "source": [
    "## Regresje liniowe z ulepszeniami\n",
    "### Liniowa regresja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression with exams\n",
      "Average: 1.360\n",
      "Standard deviation: 0.312\n",
      "Linear Regression without exams\n",
      "Average: 2.763\n",
      "Standard deviation: 0.706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "linreg = TransformedTargetRegressor(LinearRegression(), inverse_func = convert_to_int)\n",
    "\n",
    "result_with = cross_validate(linreg, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "result_without = cross_validate(linreg, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "\n",
    "\n",
    "total_results_with = append_to_results(total_results_with, \"Linear Regression\", result_with.get('test_rmse'))\n",
    "\n",
    "total_results_without = append_to_results(total_results_without, \"Linear Regression\", result_without.get('test_rmse'))\n",
    "            \n",
    "print(\"Linear Regression with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))\n",
    "\n",
    "print(\"Linear Regression without exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wielomianowa regresja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_categorical = grades_df.select_dtypes(include=np.number).columns.tolist()\n",
    "not_categorical.remove('G3')\n",
    "not_categorical_mod = not_categorical.copy()\n",
    "not_categorical_mod.remove('G2')\n",
    "not_categorical_mod.remove('G1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression with exams\n",
      "Average: 1.697\n",
      "Standard deviation: 0.334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "poly_with = ColumnTransformer([\n",
    "                          ('Poly', PolynomialFeatures(2, include_bias=False), not_categorical)\n",
    "                          ],\n",
    "                         remainder='passthrough'\n",
    ")\n",
    "\n",
    "polyreg_with = Pipeline([\n",
    "                    (\"Poly\", poly_with),\n",
    "                    (\"Logreg\", LinearRegression())\n",
    "])\n",
    "\n",
    "polyreg_with = TransformedTargetRegressor(polyreg_with, inverse_func=convert_to_int)\n",
    "\n",
    "result_with  = cross_validate(polyreg_with, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "\n",
    "total_results_with = append_to_results(total_results_with, \"Polynomial Regression\", result_with.get('test_rmse'))\n",
    "\n",
    "print(\"Polynomial Regression with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression without exams\n",
      "Average: 3.094\n",
      "Standard deviation: 0.514\n"
     ]
    }
   ],
   "source": [
    "poly_without = ColumnTransformer([\n",
    "                          ('Poly', PolynomialFeatures(2, include_bias=False), not_categorical_mod)\n",
    "                          ],\n",
    "                         remainder='passthrough'\n",
    ")\n",
    "\n",
    "polyreg_without = Pipeline([\n",
    "                    (\"Poly\", poly_without),\n",
    "                    (\"Logreg\", LinearRegression())\n",
    "])\n",
    "\n",
    "polyreg_without = TransformedTargetRegressor(polyreg_without, inverse_func=convert_to_int)\n",
    "result_without = cross_validate(polyreg_without, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "\n",
    "total_results_without = append_to_results(total_results_without, \"Polynomial Regression\", result_without.get('test_rmse'))\n",
    "\n",
    "print(\"Polynomial Regression without exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W obu przypadkach uzyskaliśmy gorsze wyniki bo sieć overfittuje, mamy za dużo featureów. Spróbujmy wybrać podzbiór najbardziej istotnych featureów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wielomianowa regresja z wyborem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression with\n",
      "feature selection with exams\n",
      "Average: 1.331\n",
      "Standard deviation: 0.331\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, f_classif\n",
    "\n",
    "poly_with = ColumnTransformer([\n",
    "                          ('Poly', PolynomialFeatures(2, include_bias=False), not_categorical)\n",
    "                          ],\n",
    "                         remainder='passthrough'\n",
    ")\n",
    "\n",
    "select_with = Pipeline([\n",
    "                    (\"Poly\", poly_with),\n",
    "                    (\"Select\", SelectKBest(f_regression, 26)),\n",
    "                    (\"Logreg\", LinearRegression())\n",
    "])\n",
    "\n",
    "select_with = TransformedTargetRegressor(select_with, inverse_func=convert_to_int)\n",
    "\n",
    "result_with  = cross_validate(select_with, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "\n",
    "total_results_with = append_to_results(total_results_with, \"Selected regression\", result_with.get('test_rmse'))\n",
    "\n",
    "print(\"Polynomial Regression with\\nfeature selection with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression with\n",
      "feature selection without exams\n",
      "Average: 2.760\n",
      "Standard deviation: 0.660\n"
     ]
    }
   ],
   "source": [
    "poly_without = ColumnTransformer([\n",
    "                          ('Poly', PolynomialFeatures(2, include_bias=False), not_categorical_mod)\n",
    "                          ],\n",
    "                         remainder='passthrough'\n",
    ")\n",
    "\n",
    "select_without = Pipeline([\n",
    "                    (\"Poly\", poly_without),\n",
    "                    (\"Select\", SelectKBest(f_regression, 26)),\n",
    "                    (\"Logreg\", LinearRegression())\n",
    "])\n",
    "\n",
    "select_without = TransformedTargetRegressor(select_without, inverse_func=convert_to_int)\n",
    "\n",
    "result_without = cross_validate(select_without, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "\n",
    "total_results_without = append_to_results(total_results_without, \"Selected regression\", result_without.get('test_rmse'))\n",
    "\n",
    "print(\"Polynomial Regression with\\nfeature selection without exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uzyskaliśmy wyniki delikatnie lepsze od najprotszej regresji liniowej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiEyeyv41jdd"
   },
   "source": [
    "## SVR\n",
    "### SVR z egzaminami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor__C</th>\n",
       "      <th>param_regressor__gamma</th>\n",
       "      <th>param_regressor__kernel</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>80</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.392449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.398001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>160</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.403755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.409240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.417804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.419929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.436393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.436738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.436929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.438618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.627757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.630023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.638818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.644356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.646406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.666147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.695128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>160</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.706707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>80</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.706707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>40</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.707704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2.928034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>80</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>40</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>160</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>4.190936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>5.732112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>8.160458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>9.818796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>13.897089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>17.971775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>40</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>34.493033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>80</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>67.469494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>160</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>133.008267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_regressor__C param_regressor__gamma param_regressor__kernel  \\\n",
       "32                 80                  scale                     rbf   \n",
       "28                 40                  scale                     rbf   \n",
       "36                160                  scale                     rbf   \n",
       "20                 15                  scale                     rbf   \n",
       "16                 10                  scale                     rbf   \n",
       "24                 20                  scale                     rbf   \n",
       "12                  8                  scale                     rbf   \n",
       "8                   5                  scale                     rbf   \n",
       "4                   3                  scale                     rbf   \n",
       "0                   1                  scale                     rbf   \n",
       "6                   3                   auto                     rbf   \n",
       "14                  8                   auto                     rbf   \n",
       "18                 10                   auto                     rbf   \n",
       "10                  5                   auto                     rbf   \n",
       "22                 15                   auto                     rbf   \n",
       "26                 20                   auto                     rbf   \n",
       "2                   1                   auto                     rbf   \n",
       "38                160                   auto                     rbf   \n",
       "34                 80                   auto                     rbf   \n",
       "30                 40                   auto                     rbf   \n",
       "1                   1                  scale                 sigmoid   \n",
       "35                 80                   auto                 sigmoid   \n",
       "27                 20                   auto                 sigmoid   \n",
       "31                 40                   auto                 sigmoid   \n",
       "19                 10                   auto                 sigmoid   \n",
       "15                  8                   auto                 sigmoid   \n",
       "11                  5                   auto                 sigmoid   \n",
       "7                   3                   auto                 sigmoid   \n",
       "3                   1                   auto                 sigmoid   \n",
       "23                 15                   auto                 sigmoid   \n",
       "39                160                   auto                 sigmoid   \n",
       "5                   3                  scale                 sigmoid   \n",
       "9                   5                  scale                 sigmoid   \n",
       "13                  8                  scale                 sigmoid   \n",
       "17                 10                  scale                 sigmoid   \n",
       "21                 15                  scale                 sigmoid   \n",
       "25                 20                  scale                 sigmoid   \n",
       "29                 40                  scale                 sigmoid   \n",
       "33                 80                  scale                 sigmoid   \n",
       "37                160                  scale                 sigmoid   \n",
       "\n",
       "    mean_test_rmse  \n",
       "32        1.392449  \n",
       "28        1.398001  \n",
       "36        1.403755  \n",
       "20        1.409240  \n",
       "16        1.417804  \n",
       "24        1.419929  \n",
       "12        1.436393  \n",
       "8         1.436738  \n",
       "4         1.436929  \n",
       "0         1.438618  \n",
       "6         1.627757  \n",
       "14        1.630023  \n",
       "18        1.638818  \n",
       "10        1.644356  \n",
       "22        1.646406  \n",
       "26        1.666147  \n",
       "2         1.695128  \n",
       "38        1.706707  \n",
       "34        1.706707  \n",
       "30        1.707704  \n",
       "1         2.928034  \n",
       "35        3.224531  \n",
       "27        3.224531  \n",
       "31        3.224531  \n",
       "19        3.224531  \n",
       "15        3.224531  \n",
       "11        3.224531  \n",
       "7         3.224531  \n",
       "3         3.224531  \n",
       "23        3.224531  \n",
       "39        3.224531  \n",
       "5         4.190936  \n",
       "9         5.732112  \n",
       "13        8.160458  \n",
       "17        9.818796  \n",
       "21       13.897089  \n",
       "25       17.971775  \n",
       "29       34.493033  \n",
       "33       67.469494  \n",
       "37      133.008267  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = TransformedTargetRegressor(SVR(), inverse_func = convert_to_int)\n",
    "\n",
    "parameters = {\"regressor__gamma\": ['scale', 'auto'],\n",
    "              \"regressor__kernel\": ['rbf', 'sigmoid'],\n",
    "              \"regressor__C\": [1.0, 3.0, 5.0, 8.0, 10, 15, 20, 40, 80, 160]}\n",
    "\n",
    "svr_grid = GridSearchCV(svr, param_grid=parameters, scoring=metrics, refit=\"rmse\", cv=5)\n",
    "svr_grid.fit(X_with_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(svr_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_regressor')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy, czy standaryzacja naszych modeli pomoże nam uzyskać lepsze wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor__SVR__C</th>\n",
       "      <th>param_regressor__SVR__gamma</th>\n",
       "      <th>param_regressor__SVR__kernel</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.598007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.598007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.605630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.605630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.614724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.614724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>160</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.617249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.617249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>80</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.617249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>160</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.617249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.617249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.617249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.617732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.617732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.619445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.619445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.626462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.626462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.766011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.766011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_regressor__SVR__C param_regressor__SVR__gamma  \\\n",
       "4                        5                       scale   \n",
       "5                        5                        auto   \n",
       "6                        8                       scale   \n",
       "7                        8                        auto   \n",
       "10                      15                       scale   \n",
       "11                      15                        auto   \n",
       "19                     160                        auto   \n",
       "17                      80                        auto   \n",
       "16                      80                       scale   \n",
       "18                     160                       scale   \n",
       "14                      40                       scale   \n",
       "15                      40                        auto   \n",
       "12                      20                       scale   \n",
       "13                      20                        auto   \n",
       "2                        3                       scale   \n",
       "3                        3                        auto   \n",
       "9                       10                        auto   \n",
       "8                       10                       scale   \n",
       "1                        1                        auto   \n",
       "0                        1                       scale   \n",
       "\n",
       "   param_regressor__SVR__kernel  mean_test_rmse  \n",
       "4                           rbf        1.598007  \n",
       "5                           rbf        1.598007  \n",
       "6                           rbf        1.605630  \n",
       "7                           rbf        1.605630  \n",
       "10                          rbf        1.614724  \n",
       "11                          rbf        1.614724  \n",
       "19                          rbf        1.617249  \n",
       "17                          rbf        1.617249  \n",
       "16                          rbf        1.617249  \n",
       "18                          rbf        1.617249  \n",
       "14                          rbf        1.617249  \n",
       "15                          rbf        1.617249  \n",
       "12                          rbf        1.617732  \n",
       "13                          rbf        1.617732  \n",
       "2                           rbf        1.619445  \n",
       "3                           rbf        1.619445  \n",
       "9                           rbf        1.626462  \n",
       "8                           rbf        1.626462  \n",
       "1                           rbf        1.766011  \n",
       "0                           rbf        1.766011  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standsvr = Pipeline([\n",
    "    (\"Standard Scaler\", StandardScaler()),\n",
    "    (\"SVR\", SVR())\n",
    "])\n",
    "\n",
    "standsvr = TransformedTargetRegressor(standsvr, inverse_func = convert_to_int)\n",
    "\n",
    "svr.get_params().keys()\n",
    "parameters = {\"regressor__SVR__gamma\": ['scale', 'auto'],\n",
    "              \"regressor__SVR__kernel\": ['rbf'],\n",
    "              \"regressor__SVR__C\": [1.0, 3.0, 5.0, 8.0, 10, 15, 20, 40, 80, 160]}\n",
    "\n",
    "svr_grid = GridSearchCV(standsvr, param_grid=parameters, scoring=metrics, refit=\"rmse\", cv=5)\n",
    "svr_grid.fit(X_with_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(svr_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_regressor')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standaryzacja nie pomogła. Poniżej najlepszy wynik jakie uzyskał SVR z egzaminami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with exams\n",
      "Average: 1.392\n",
      "Standard deviation: 0.387\n"
     ]
    }
   ],
   "source": [
    "svr = TransformedTargetRegressor(\n",
    "    SVR(C=80, gamma='scale', kernel='rbf'),\n",
    "    inverse_func=convert_to_int)\n",
    "\n",
    "result_with = cross_validate(svr, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "\n",
    "total_results_with = append_to_results(total_results_with, \"SVR\", result_with.get('test_rmse'))\n",
    "\n",
    "print(\"SVR with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR bez egzaminów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor__C</th>\n",
       "      <th>param_regressor__gamma</th>\n",
       "      <th>param_regressor__kernel</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.704229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.738237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.749441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>40</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.751605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.760755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.761104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>80</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.775310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.785476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.805925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.808733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.825714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>160</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.840074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.846066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.883358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.900317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.913971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>2.979025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>40</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.038921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.051230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>80</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.166988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>40</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>80</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>160</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.224531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>160</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.244216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.331723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>4.801687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>6.059772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>9.288568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>12.486324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>40</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>24.948278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>80</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>49.543235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>160</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>98.418901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_regressor__C param_regressor__gamma param_regressor__kernel  \\\n",
       "16                 10                  scale                     rbf   \n",
       "20                 15                  scale                     rbf   \n",
       "24                 20                  scale                     rbf   \n",
       "12                  8                  scale                     rbf   \n",
       "28                 40                  scale                     rbf   \n",
       "4                   3                  scale                     rbf   \n",
       "8                   5                  scale                     rbf   \n",
       "32                 80                  scale                     rbf   \n",
       "6                   3                   auto                     rbf   \n",
       "10                  5                   auto                     rbf   \n",
       "2                   1                   auto                     rbf   \n",
       "14                  8                   auto                     rbf   \n",
       "36                160                  scale                     rbf   \n",
       "18                 10                   auto                     rbf   \n",
       "22                 15                   auto                     rbf   \n",
       "0                   1                  scale                     rbf   \n",
       "26                 20                   auto                     rbf   \n",
       "5                   3                  scale                 sigmoid   \n",
       "30                 40                   auto                     rbf   \n",
       "1                   1                  scale                 sigmoid   \n",
       "34                 80                   auto                     rbf   \n",
       "31                 40                   auto                 sigmoid   \n",
       "27                 20                   auto                 sigmoid   \n",
       "35                 80                   auto                 sigmoid   \n",
       "19                 10                   auto                 sigmoid   \n",
       "15                  8                   auto                 sigmoid   \n",
       "11                  5                   auto                 sigmoid   \n",
       "7                   3                   auto                 sigmoid   \n",
       "3                   1                   auto                 sigmoid   \n",
       "23                 15                   auto                 sigmoid   \n",
       "39                160                   auto                 sigmoid   \n",
       "38                160                   auto                     rbf   \n",
       "9                   5                  scale                 sigmoid   \n",
       "13                  8                  scale                 sigmoid   \n",
       "17                 10                  scale                 sigmoid   \n",
       "21                 15                  scale                 sigmoid   \n",
       "25                 20                  scale                 sigmoid   \n",
       "29                 40                  scale                 sigmoid   \n",
       "33                 80                  scale                 sigmoid   \n",
       "37                160                  scale                 sigmoid   \n",
       "\n",
       "    mean_test_rmse  \n",
       "16        2.704229  \n",
       "20        2.728333  \n",
       "24        2.738237  \n",
       "12        2.749441  \n",
       "28        2.751605  \n",
       "4         2.760755  \n",
       "8         2.761104  \n",
       "32        2.775310  \n",
       "6         2.785476  \n",
       "10        2.805925  \n",
       "2         2.808733  \n",
       "14        2.825714  \n",
       "36        2.840074  \n",
       "18        2.846066  \n",
       "22        2.883358  \n",
       "0         2.900317  \n",
       "26        2.913971  \n",
       "5         2.979025  \n",
       "30        3.038921  \n",
       "1         3.051230  \n",
       "34        3.166988  \n",
       "31        3.224531  \n",
       "27        3.224531  \n",
       "35        3.224531  \n",
       "19        3.224531  \n",
       "15        3.224531  \n",
       "11        3.224531  \n",
       "7         3.224531  \n",
       "3         3.224531  \n",
       "23        3.224531  \n",
       "39        3.224531  \n",
       "38        3.244216  \n",
       "9         3.331723  \n",
       "13        4.801687  \n",
       "17        6.059772  \n",
       "21        9.288568  \n",
       "25       12.486324  \n",
       "29       24.948278  \n",
       "33       49.543235  \n",
       "37       98.418901  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = TransformedTargetRegressor(SVR(), inverse_func = convert_to_int)\n",
    "\n",
    "parameters = {\"regressor__gamma\": ['scale', 'auto'],\n",
    "              \"regressor__kernel\": ['rbf', 'sigmoid'],\n",
    "              \"regressor__C\": [1.0, 3.0, 5.0, 8.0, 10, 15, 20, 40, 80, 160]}\n",
    "\n",
    "svr_grid = GridSearchCV(svr, param_grid=parameters, scoring=metrics, refit=\"rmse\", cv=5)\n",
    "svr_grid.fit(X_without_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(svr_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_regressor')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy, czy tu standaryzacja pomoże.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor__SVR__C</th>\n",
       "      <th>param_regressor__SVR__gamma</th>\n",
       "      <th>param_regressor__SVR__kernel</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.698487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.698487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.704005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.704005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.704524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.704524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.740643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.740643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.743775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.743775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.777925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.777925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.813814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.813814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.848082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.848082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>160</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.861145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>80</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.861145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.861145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>160</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>2.861145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_regressor__SVR__C param_regressor__SVR__gamma  \\\n",
       "2                        3                       scale   \n",
       "3                        3                        auto   \n",
       "0                        1                       scale   \n",
       "1                        1                        auto   \n",
       "4                        5                       scale   \n",
       "5                        5                        auto   \n",
       "6                        8                       scale   \n",
       "7                        8                        auto   \n",
       "9                       10                        auto   \n",
       "8                       10                       scale   \n",
       "10                      15                       scale   \n",
       "11                      15                        auto   \n",
       "12                      20                       scale   \n",
       "13                      20                        auto   \n",
       "14                      40                       scale   \n",
       "15                      40                        auto   \n",
       "18                     160                       scale   \n",
       "16                      80                       scale   \n",
       "17                      80                        auto   \n",
       "19                     160                        auto   \n",
       "\n",
       "   param_regressor__SVR__kernel  mean_test_rmse  \n",
       "2                           rbf        2.698487  \n",
       "3                           rbf        2.698487  \n",
       "0                           rbf        2.704005  \n",
       "1                           rbf        2.704005  \n",
       "4                           rbf        2.704524  \n",
       "5                           rbf        2.704524  \n",
       "6                           rbf        2.740643  \n",
       "7                           rbf        2.740643  \n",
       "9                           rbf        2.743775  \n",
       "8                           rbf        2.743775  \n",
       "10                          rbf        2.777925  \n",
       "11                          rbf        2.777925  \n",
       "12                          rbf        2.813814  \n",
       "13                          rbf        2.813814  \n",
       "14                          rbf        2.848082  \n",
       "15                          rbf        2.848082  \n",
       "18                          rbf        2.861145  \n",
       "16                          rbf        2.861145  \n",
       "17                          rbf        2.861145  \n",
       "19                          rbf        2.861145  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standsvr = Pipeline([\n",
    "    (\"Standard Scaler\", StandardScaler()),\n",
    "    (\"SVR\", SVR())\n",
    "])\n",
    "\n",
    "standsvr = TransformedTargetRegressor(standsvr, inverse_func = convert_to_int)\n",
    "\n",
    "parameters = {\"regressor__SVR__gamma\": ['scale', 'auto'],\n",
    "              \"regressor__SVR__kernel\": ['rbf'],\n",
    "              \"regressor__SVR__C\": [1.0, 3.0, 5.0, 8.0, 10, 15, 20, 40, 80, 160]}\n",
    "\n",
    "svr_grid = GridSearchCV(standsvr, param_grid=parameters, scoring=metrics, refit=\"rmse\", cv=5)\n",
    "svr_grid.fit(X_without_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(svr_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_regressor')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR without exams\n",
      "Average: 2.698\n",
      "Standard deviation: 0.705\n"
     ]
    }
   ],
   "source": [
    "svr_without = Pipeline([\n",
    "    (\"Standard Scaler\", StandardScaler()),\n",
    "    (\"SVR\", SVR(C=3, kernel='rbf', gamma='scale'))\n",
    "])\n",
    "\n",
    "svr_without = TransformedTargetRegressor(svr_without, inverse_func = convert_to_int)\n",
    "\n",
    "result_without = cross_validate(svr_without, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "\n",
    "total_results_without = append_to_results(total_results_without, \"SVR\", result_without.get('test_rmse'))\n",
    "\n",
    "print(\"SVR without exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PIsJnW3xDi2"
   },
   "source": [
    "## Sieci neuronowe\n",
    "### Sieci neuronowe z egzaminami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "pvmxIe6GxF0m"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor__alpha</th>\n",
       "      <th>param_regressor__hidden_layer_sizes</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>1.477730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>1.503616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>1.523967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>1.526095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>1.532309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>1.538103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>1.541354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>1.542337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>1.542785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>1.545801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>1.551251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>1.560610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>1.560958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>1.562163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>1.568911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>1.575766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>1.577990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>1.584766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>1.585845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>1.599264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>1.606278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>1.613482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>1.614681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>1.624397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_regressor__alpha param_regressor__hidden_layer_sizes  mean_test_rmse\n",
       "0                   0.001                            (32, 32)        1.477730\n",
       "17                 0.0001                        (52, 52, 52)        1.503616\n",
       "22                 0.0003                        (42, 42, 42)        1.523967\n",
       "23                 0.0003                        (52, 52, 52)        1.526095\n",
       "7                   0.003                            (48, 48)        1.532309\n",
       "12                 0.0001                            (32, 32)        1.538103\n",
       "11                  0.003                        (52, 52, 52)        1.541354\n",
       "5                   0.001                        (52, 52, 52)        1.542337\n",
       "9                   0.003                        (32, 32, 32)        1.542785\n",
       "21                 0.0003                        (32, 32, 32)        1.545801\n",
       "19                 0.0003                            (48, 48)        1.551251\n",
       "18                 0.0003                            (32, 32)        1.560610\n",
       "14                 0.0001                            (64, 64)        1.560958\n",
       "15                 0.0001                        (32, 32, 32)        1.562163\n",
       "1                   0.001                            (48, 48)        1.568911\n",
       "20                 0.0003                            (64, 64)        1.575766\n",
       "13                 0.0001                            (48, 48)        1.577990\n",
       "6                   0.003                            (32, 32)        1.584766\n",
       "4                   0.001                        (42, 42, 42)        1.585845\n",
       "8                   0.003                            (64, 64)        1.599264\n",
       "10                  0.003                        (42, 42, 42)        1.606278\n",
       "2                   0.001                            (64, 64)        1.613482\n",
       "16                 0.0001                        (42, 42, 42)        1.614681\n",
       "3                   0.001                        (32, 32, 32)        1.624397"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "neur_net = MLPRegressor(solver='lbfgs', random_state=1)\n",
    "\n",
    "neur_net = TransformedTargetRegressor(neur_net, inverse_func=convert_to_int)\n",
    "parameters = {'regressor__hidden_layer_sizes': [(32, 32), (48, 48), (64, 64), (32, 32, 32), (42, 42, 42), (52, 52, 52)],\n",
    "             'regressor__alpha': [0.001, 0.003, 0.0001, 0.0003]}\n",
    "\n",
    "nngrid = GridSearchCV(neur_net, param_grid=parameters, scoring=metrics, refit=\"rmse\", cv=5)\n",
    "nngrid.fit(X_with_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(nngrid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_regressor')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy, czy standaryzacja pozwoli uzyskać lepsze wyniki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor__regressor__NeuralNetwork__alpha</th>\n",
       "      <th>param_regressor__regressor__NeuralNetwork__hidden_layer_sizes</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>1.658987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>1.686443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>1.688496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>1.692928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>1.703641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>1.717802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>1.726049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>1.728363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>1.739293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>1.745699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>1.747831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>1.748507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>1.750614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>1.756672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>1.759786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>1.760622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>1.772255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>1.773204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>1.774310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>1.774800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>1.775828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>1.776739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>1.782741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>1.790890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_regressor__regressor__NeuralNetwork__alpha  \\\n",
       "4                                             0.001   \n",
       "22                                           0.0003   \n",
       "16                                           0.0001   \n",
       "10                                            0.003   \n",
       "9                                             0.003   \n",
       "3                                             0.001   \n",
       "21                                           0.0003   \n",
       "15                                           0.0001   \n",
       "0                                             0.001   \n",
       "7                                             0.003   \n",
       "13                                           0.0001   \n",
       "1                                             0.001   \n",
       "6                                             0.003   \n",
       "19                                           0.0003   \n",
       "18                                           0.0003   \n",
       "12                                           0.0001   \n",
       "8                                             0.003   \n",
       "5                                             0.001   \n",
       "17                                           0.0001   \n",
       "23                                           0.0003   \n",
       "2                                             0.001   \n",
       "20                                           0.0003   \n",
       "14                                           0.0001   \n",
       "11                                            0.003   \n",
       "\n",
       "   param_regressor__regressor__NeuralNetwork__hidden_layer_sizes  \\\n",
       "4                                        (42, 42, 42)              \n",
       "22                                       (42, 42, 42)              \n",
       "16                                       (42, 42, 42)              \n",
       "10                                       (42, 42, 42)              \n",
       "9                                        (32, 32, 32)              \n",
       "3                                        (32, 32, 32)              \n",
       "21                                       (32, 32, 32)              \n",
       "15                                       (32, 32, 32)              \n",
       "0                                            (32, 32)              \n",
       "7                                            (48, 48)              \n",
       "13                                           (48, 48)              \n",
       "1                                            (48, 48)              \n",
       "6                                            (32, 32)              \n",
       "19                                           (48, 48)              \n",
       "18                                           (32, 32)              \n",
       "12                                           (32, 32)              \n",
       "8                                            (64, 64)              \n",
       "5                                        (52, 52, 52)              \n",
       "17                                       (52, 52, 52)              \n",
       "23                                       (52, 52, 52)              \n",
       "2                                            (64, 64)              \n",
       "20                                           (64, 64)              \n",
       "14                                           (64, 64)              \n",
       "11                                       (52, 52, 52)              \n",
       "\n",
       "    mean_test_rmse  \n",
       "4         1.658987  \n",
       "22        1.686443  \n",
       "16        1.688496  \n",
       "10        1.692928  \n",
       "9         1.703641  \n",
       "3         1.717802  \n",
       "21        1.726049  \n",
       "15        1.728363  \n",
       "0         1.739293  \n",
       "7         1.745699  \n",
       "13        1.747831  \n",
       "1         1.748507  \n",
       "6         1.750614  \n",
       "19        1.756672  \n",
       "18        1.759786  \n",
       "12        1.760622  \n",
       "8         1.772255  \n",
       "5         1.773204  \n",
       "17        1.774310  \n",
       "23        1.774800  \n",
       "2         1.775828  \n",
       "20        1.776739  \n",
       "14        1.782741  \n",
       "11        1.790890  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neur_net = Pipeline([\n",
    "    (\"StandardScaler\", StandardScaler()),\n",
    "    (\"NeuralNetwork\", MLPRegressor(solver='lbfgs', random_state=1))\n",
    "])\n",
    "\n",
    "neur_net = TransformedTargetRegressor(neur_net, transformer=StandardScaler())\n",
    "neur_net = TransformedTargetRegressor(neur_net, inverse_func=convert_to_int)\n",
    "\n",
    "parameters = {'regressor__regressor__NeuralNetwork__hidden_layer_sizes': [(32, 32), (48, 48), (64, 64), (32, 32, 32), (42, 42, 42), (52, 52, 52)],\n",
    "              'regressor__regressor__NeuralNetwork__alpha': [0.001, 0.003, 0.0001, 0.0003]}\n",
    "\n",
    "neur_net.get_params().keys()\n",
    "nngrid = GridSearchCV(neur_net, param_grid=parameters, scoring=metrics, refit=\"rmse\", cv=5)\n",
    "nngrid.fit(X_with_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(nngrid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_regressor')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najlepszy model dla danych z egzaminami uzyskaliśmy w modelu bez standaryzacji. Poniżej ten model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network with exams\n",
      "Average: 1.524\n",
      "Standard deviation: 0.312\n"
     ]
    }
   ],
   "source": [
    "neur_net = MLPRegressor(solver='lbfgs', hidden_layer_sizes=(42, 42, 42), alpha=0.0003, random_state=1)\n",
    "\n",
    "neur_net = TransformedTargetRegressor(neur_net, inverse_func=convert_to_int)\n",
    "\n",
    "result_with = cross_validate(neur_net, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "\n",
    "total_results_with = append_to_results(total_results_with, \"Neural Network\", result_with.get('test_rmse'))\n",
    "\n",
    "print(\"Neural Network with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdraYvCD4ckV"
   },
   "source": [
    "### Sieć bez wyników egzaminu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "xZcVGs_o4cQY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor__alpha</th>\n",
       "      <th>param_regressor__hidden_layer_sizes</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>2.898607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>2.900604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>2.928879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>2.970843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>3.009072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>3.014453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>3.032767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>3.045812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>3.078187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>3.133301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>3.137394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>3.171255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(52, 52, 52)</td>\n",
       "      <td>3.173082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>3.173749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>3.187532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>3.191720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>3.202715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>3.260691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(42, 42, 42)</td>\n",
       "      <td>3.287775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>3.303482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>3.340310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>3.356551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>3.363977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>3.372527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_regressor__alpha param_regressor__hidden_layer_sizes  mean_test_rmse\n",
       "15                 0.0001                        (32, 32, 32)        2.898607\n",
       "21                 0.0003                        (32, 32, 32)        2.900604\n",
       "9                   0.003                        (32, 32, 32)        2.928879\n",
       "3                   0.001                        (32, 32, 32)        2.970843\n",
       "0                   0.001                            (32, 32)        3.009072\n",
       "12                 0.0001                            (32, 32)        3.014453\n",
       "18                 0.0003                            (32, 32)        3.032767\n",
       "6                   0.003                            (32, 32)        3.045812\n",
       "23                 0.0003                        (52, 52, 52)        3.078187\n",
       "17                 0.0001                        (52, 52, 52)        3.133301\n",
       "11                  0.003                        (52, 52, 52)        3.137394\n",
       "13                 0.0001                            (48, 48)        3.171255\n",
       "5                   0.001                        (52, 52, 52)        3.173082\n",
       "7                   0.003                            (48, 48)        3.173749\n",
       "22                 0.0003                        (42, 42, 42)        3.187532\n",
       "19                 0.0003                            (48, 48)        3.191720\n",
       "16                 0.0001                        (42, 42, 42)        3.202715\n",
       "4                   0.001                        (42, 42, 42)        3.260691\n",
       "10                  0.003                        (42, 42, 42)        3.287775\n",
       "1                   0.001                            (48, 48)        3.303482\n",
       "14                 0.0001                            (64, 64)        3.340310\n",
       "20                 0.0003                            (64, 64)        3.356551\n",
       "2                   0.001                            (64, 64)        3.363977\n",
       "8                   0.003                            (64, 64)        3.372527"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neur_net = MLPRegressor(solver='lbfgs', random_state=1)\n",
    "\n",
    "neur_net = TransformedTargetRegressor(neur_net, inverse_func=convert_to_int)\n",
    "parameters = {'regressor__hidden_layer_sizes': [(32, 32), (48, 48), (64, 64), (32, 32, 32), (42, 42, 42), (52, 52, 52)],\n",
    "             'regressor__alpha': [0.001, 0.003, 0.0001, 0.0003]}\n",
    "\n",
    "nngrid = GridSearchCV(neur_net, param_grid=parameters, scoring=metrics, refit=\"rmse\", cv=5)\n",
    "nngrid.fit(X_without_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(nngrid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_regressor')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy, czy standaryzacja pomoże."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "SsbhcCes4xNR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor__regressor__NeuralNetwork__alpha</th>\n",
       "      <th>param_regressor__regressor__NeuralNetwork__hidden_layer_sizes</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(80, 80)</td>\n",
       "      <td>3.282191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(80, 80)</td>\n",
       "      <td>3.293752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(80, 80)</td>\n",
       "      <td>3.300223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(80, 80)</td>\n",
       "      <td>3.301352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>3.326752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>3.332065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>3.343072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(48, 48)</td>\n",
       "      <td>3.344681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>3.414520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>3.427217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>3.437184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>3.437236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>3.493258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>3.513964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>3.516168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 32, 32)</td>\n",
       "      <td>3.530536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>3.641176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>3.644239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>3.653676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 32)</td>\n",
       "      <td>3.656321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>48</td>\n",
       "      <td>4.128336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>48</td>\n",
       "      <td>4.134629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>48</td>\n",
       "      <td>4.137379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003</td>\n",
       "      <td>48</td>\n",
       "      <td>4.147437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_regressor__regressor__NeuralNetwork__alpha  \\\n",
       "16                                           0.0001   \n",
       "10                                            0.003   \n",
       "4                                             0.001   \n",
       "22                                           0.0003   \n",
       "2                                             0.001   \n",
       "20                                           0.0003   \n",
       "14                                           0.0001   \n",
       "8                                             0.003   \n",
       "9                                             0.003   \n",
       "3                                             0.001   \n",
       "21                                           0.0003   \n",
       "15                                           0.0001   \n",
       "11                                            0.003   \n",
       "23                                           0.0003   \n",
       "5                                             0.001   \n",
       "17                                           0.0001   \n",
       "13                                           0.0001   \n",
       "7                                             0.003   \n",
       "19                                           0.0003   \n",
       "1                                             0.001   \n",
       "0                                             0.001   \n",
       "12                                           0.0001   \n",
       "18                                           0.0003   \n",
       "6                                             0.003   \n",
       "\n",
       "   param_regressor__regressor__NeuralNetwork__hidden_layer_sizes  \\\n",
       "16                                           (80, 80)              \n",
       "10                                           (80, 80)              \n",
       "4                                            (80, 80)              \n",
       "22                                           (80, 80)              \n",
       "2                                            (48, 48)              \n",
       "20                                           (48, 48)              \n",
       "14                                           (48, 48)              \n",
       "8                                            (48, 48)              \n",
       "9                                            (64, 64)              \n",
       "3                                            (64, 64)              \n",
       "21                                           (64, 64)              \n",
       "15                                           (64, 64)              \n",
       "11                                       (32, 32, 32)              \n",
       "23                                       (32, 32, 32)              \n",
       "5                                        (32, 32, 32)              \n",
       "17                                       (32, 32, 32)              \n",
       "13                                           (32, 32)              \n",
       "7                                            (32, 32)              \n",
       "19                                           (32, 32)              \n",
       "1                                            (32, 32)              \n",
       "0                                                  48              \n",
       "12                                                 48              \n",
       "18                                                 48              \n",
       "6                                                  48              \n",
       "\n",
       "    mean_test_rmse  \n",
       "16        3.282191  \n",
       "10        3.293752  \n",
       "4         3.300223  \n",
       "22        3.301352  \n",
       "2         3.326752  \n",
       "20        3.332065  \n",
       "14        3.343072  \n",
       "8         3.344681  \n",
       "9         3.414520  \n",
       "3         3.427217  \n",
       "21        3.437184  \n",
       "15        3.437236  \n",
       "11        3.493258  \n",
       "23        3.513964  \n",
       "5         3.516168  \n",
       "17        3.530536  \n",
       "13        3.641176  \n",
       "7         3.644239  \n",
       "19        3.653676  \n",
       "1         3.656321  \n",
       "0         4.128336  \n",
       "12        4.134629  \n",
       "18        4.137379  \n",
       "6         4.147437  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neur_net = Pipeline([\n",
    "    (\"StandardScaler\", StandardScaler()),\n",
    "    (\"NeuralNetwork\", MLPRegressor(solver='lbfgs', random_state=1))\n",
    "])\n",
    "\n",
    "neur_net = TransformedTargetRegressor(neur_net, transformer=StandardScaler())\n",
    "neur_net = TransformedTargetRegressor(neur_net, inverse_func=convert_to_int)\n",
    "\n",
    "parameters = {'regressor__regressor__NeuralNetwork__hidden_layer_sizes': [(48), (32, 32), (48, 48), (64, 64), (80, 80), (32, 32, 32)],\n",
    "              'regressor__regressor__NeuralNetwork__alpha': [0.001, 0.003, 0.0001, 0.0003]}\n",
    "\n",
    "neur_net.get_params().keys()\n",
    "nngrid = GridSearchCV(neur_net, param_grid=parameters, scoring=metrics, refit=\"rmse\", cv=5)\n",
    "nngrid.fit(X_without_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(nngrid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_regressor')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QeGNGsur6mR"
   },
   "source": [
    "Najlepszy model sieci bez wyników egzaminu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network without exams\n",
      "Average: 3.288\n",
      "Standard deviation: 0.544\n"
     ]
    }
   ],
   "source": [
    "neur_net = MLPRegressor(solver='lbfgs', hidden_layer_sizes=(42, 42, 42), alpha=0.003, random_state=1)\n",
    "\n",
    "neur_net = TransformedTargetRegressor(neur_net, inverse_func=convert_to_int)\n",
    "\n",
    "result_without = cross_validate(neur_net, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "\n",
    "total_results_without = append_to_results(total_results_without, \"Neural Network\", result_without.get('test_rmse'))\n",
    "\n",
    "print(\"Neural Network without exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "### XGBoost z egzaminami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor__max_depth</th>\n",
       "      <th>param_regressor__subsample</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1.449083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.452146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.452704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.453863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.456678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.461571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.468500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.473021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.473436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.481242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_regressor__max_depth param_regressor__subsample  mean_test_rmse\n",
       "9                         18                          1        1.449083\n",
       "3                          9                          1        1.452146\n",
       "6                         14                        0.8        1.452704\n",
       "4                         11                        0.8        1.453863\n",
       "7                         14                          1        1.456678\n",
       "8                         18                        0.8        1.461571\n",
       "5                         11                          1        1.468500\n",
       "2                          9                        0.8        1.473021\n",
       "0                          7                        0.8        1.473436\n",
       "1                          7                          1        1.481242"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(booster='gbtree')\n",
    "xgb = TransformedTargetRegressor(xgb, inverse_func=convert_to_int)\n",
    "parameters = {\"regressor__max_depth\": [7, 9, 11, 14, 18],\n",
    "             \"regressor__subsample\": [0.8, 1]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb, scoring=metrics, param_grid=parameters, refit=\"rmse\", cv=5)\n",
    "xgb_grid.fit(X_with_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(xgb_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_regressor')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost with exams\n",
      "Average: 1.453\n",
      "Standard deviation: 0.266\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(booster='gbtree', max_depth=14, subsample=0.8)\n",
    "xgb = TransformedTargetRegressor(xgb, inverse_func=convert_to_int)\n",
    "\n",
    "result_with = cross_validate(xgb, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "\n",
    "total_results_with = append_to_results(total_results_with, \"XGBoost Regressor\", result_with.get('test_rmse'))\n",
    "\n",
    "print(\"XGBoost with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost bez egzaminów "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_regressor__max_depth</th>\n",
       "      <th>param_regressor__subsample</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.987526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2.996817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.997721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.998963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2.999007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.005953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.035698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3.044838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.049108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.052754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.059751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.074221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_regressor__max_depth param_regressor__subsample  mean_test_rmse\n",
       "1                           5                          1        2.987526\n",
       "5                           9                          1        2.996817\n",
       "7                          11                          1        2.997721\n",
       "8                          14                        0.8        2.998963\n",
       "3                           7                          1        2.999007\n",
       "10                         18                        0.8        3.005953\n",
       "11                         18                          1        3.035698\n",
       "9                          14                          1        3.044838\n",
       "4                           9                        0.8        3.049108\n",
       "2                           7                        0.8        3.052754\n",
       "6                          11                        0.8        3.059751\n",
       "0                           5                        0.8        3.074221"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(booster='gbtree')\n",
    "xgb = TransformedTargetRegressor(xgb, inverse_func=convert_to_int)\n",
    "parameters = {\"regressor__max_depth\": [5, 7, 9, 11, 14, 18],\n",
    "             \"regressor__subsample\": [0.8, 1]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb, scoring=metrics, param_grid=parameters, refit=\"rmse\", cv=5)\n",
    "xgb_grid.fit(X_without_exams, Y)\n",
    "\n",
    "grid = pd.DataFrame(xgb_grid.cv_results_).sort_values(by='mean_test_rmse')\n",
    "filter_col = [col for col in grid if col.startswith('param_regressor')]\n",
    "filter_col.append('mean_test_rmse')\n",
    "grid[filter_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost with exams\n",
      "Average: 3.053\n",
      "Standard deviation: 0.578\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(booster='gbtree', max_depth=7, subsample=0.8)\n",
    "xgb = TransformedTargetRegressor(xgb, inverse_func=convert_to_int)\n",
    "\n",
    "result_without = cross_validate(xgb, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "\n",
    "total_results_without = append_to_results(total_results_without, \"XGBoost Regressor\", result_without.get('test_rmse'))\n",
    "\n",
    "print(\"XGBoost with exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podsumowanie modeli jednostkowych\n",
    "\n",
    "## Modele z wynikami egzaminów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Selected regression</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.331076</td>\n",
       "      <td>0.369744</td>\n",
       "      <td>1.026570</td>\n",
       "      <td>1.130010</td>\n",
       "      <td>1.130010</td>\n",
       "      <td>1.435806</td>\n",
       "      <td>1.932986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.360112</td>\n",
       "      <td>0.349001</td>\n",
       "      <td>1.059753</td>\n",
       "      <td>1.189699</td>\n",
       "      <td>1.199359</td>\n",
       "      <td>1.408764</td>\n",
       "      <td>1.942986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.392449</td>\n",
       "      <td>0.432248</td>\n",
       "      <td>1.003839</td>\n",
       "      <td>1.163549</td>\n",
       "      <td>1.231010</td>\n",
       "      <td>1.454436</td>\n",
       "      <td>2.109410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Regressor</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.452704</td>\n",
       "      <td>0.296856</td>\n",
       "      <td>1.146902</td>\n",
       "      <td>1.221600</td>\n",
       "      <td>1.422349</td>\n",
       "      <td>1.588420</td>\n",
       "      <td>1.884247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.461080</td>\n",
       "      <td>0.314808</td>\n",
       "      <td>1.060203</td>\n",
       "      <td>1.270978</td>\n",
       "      <td>1.531716</td>\n",
       "      <td>1.549193</td>\n",
       "      <td>1.893308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.523967</td>\n",
       "      <td>0.348957</td>\n",
       "      <td>1.052470</td>\n",
       "      <td>1.361560</td>\n",
       "      <td>1.531716</td>\n",
       "      <td>1.691608</td>\n",
       "      <td>1.982481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.565333</td>\n",
       "      <td>0.267783</td>\n",
       "      <td>1.179961</td>\n",
       "      <td>1.400443</td>\n",
       "      <td>1.668717</td>\n",
       "      <td>1.771570</td>\n",
       "      <td>1.805973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.618472</td>\n",
       "      <td>0.412392</td>\n",
       "      <td>1.038036</td>\n",
       "      <td>1.392286</td>\n",
       "      <td>1.718676</td>\n",
       "      <td>1.843909</td>\n",
       "      <td>2.099450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial Regression</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.697249</td>\n",
       "      <td>0.373365</td>\n",
       "      <td>1.389521</td>\n",
       "      <td>1.395046</td>\n",
       "      <td>1.521639</td>\n",
       "      <td>1.963122</td>\n",
       "      <td>2.216919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       RMSE                                                    \\\n",
       "                      count      mean       std       min       25%       50%   \n",
       "Model                                                                           \n",
       "Selected regression     5.0  1.331076  0.369744  1.026570  1.130010  1.130010   \n",
       "Linear Regression       5.0  1.360112  0.349001  1.059753  1.189699  1.199359   \n",
       "SVR                     5.0  1.392449  0.432248  1.003839  1.163549  1.231010   \n",
       "XGBoost Regressor       5.0  1.452704  0.296856  1.146902  1.221600  1.422349   \n",
       "XGBoost Classifier      5.0  1.461080  0.314808  1.060203  1.270978  1.531716   \n",
       "Neural Network          5.0  1.523967  0.348957  1.052470  1.361560  1.531716   \n",
       "Decision Tree           5.0  1.565333  0.267783  1.179961  1.400443  1.668717   \n",
       "Random Forest           5.0  1.618472  0.412392  1.038036  1.392286  1.718676   \n",
       "Polynomial Regression   5.0  1.697249  0.373365  1.389521  1.395046  1.521639   \n",
       "\n",
       "                                           \n",
       "                            75%       max  \n",
       "Model                                      \n",
       "Selected regression    1.435806  1.932986  \n",
       "Linear Regression      1.408764  1.942986  \n",
       "SVR                    1.454436  2.109410  \n",
       "XGBoost Regressor      1.588420  1.884247  \n",
       "XGBoost Classifier     1.549193  1.893308  \n",
       "Neural Network         1.691608  1.982481  \n",
       "Decision Tree          1.771570  1.805973  \n",
       "Random Forest          1.843909  2.099450  \n",
       "Polynomial Regression  1.963122  2.216919  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_results_with.groupby(\"Model\").describe().sort_values(by=('RMSE','mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_results_with.groupby(\"Model\").describe().sort_values(by=('RMSE','mean')).to_latex(\"result_with.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "sns.boxplot(data=total_results_with, x=\"Model\", y=\"RMSE\", color=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele bez wyników egzaminów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.698487</td>\n",
       "      <td>0.787996</td>\n",
       "      <td>1.907475</td>\n",
       "      <td>2.424237</td>\n",
       "      <td>2.446347</td>\n",
       "      <td>2.704697</td>\n",
       "      <td>4.009678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Selected regression</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.759890</td>\n",
       "      <td>0.737478</td>\n",
       "      <td>2.123133</td>\n",
       "      <td>2.387467</td>\n",
       "      <td>2.414699</td>\n",
       "      <td>2.891632</td>\n",
       "      <td>3.982520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.762648</td>\n",
       "      <td>0.789071</td>\n",
       "      <td>2.086587</td>\n",
       "      <td>2.345208</td>\n",
       "      <td>2.452628</td>\n",
       "      <td>2.840639</td>\n",
       "      <td>4.088175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Regressor</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.052754</td>\n",
       "      <td>0.646235</td>\n",
       "      <td>2.403523</td>\n",
       "      <td>2.710379</td>\n",
       "      <td>2.859532</td>\n",
       "      <td>3.202163</td>\n",
       "      <td>4.088175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.059361</td>\n",
       "      <td>0.324533</td>\n",
       "      <td>2.728764</td>\n",
       "      <td>2.837930</td>\n",
       "      <td>2.980707</td>\n",
       "      <td>3.204564</td>\n",
       "      <td>3.544840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polynomial Regression</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.094362</td>\n",
       "      <td>0.574515</td>\n",
       "      <td>2.585462</td>\n",
       "      <td>2.785954</td>\n",
       "      <td>2.890302</td>\n",
       "      <td>3.156190</td>\n",
       "      <td>4.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.287775</td>\n",
       "      <td>0.607712</td>\n",
       "      <td>2.779042</td>\n",
       "      <td>2.896948</td>\n",
       "      <td>2.903579</td>\n",
       "      <td>3.712764</td>\n",
       "      <td>4.146541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.336951</td>\n",
       "      <td>0.367486</td>\n",
       "      <td>2.933887</td>\n",
       "      <td>2.956089</td>\n",
       "      <td>3.469649</td>\n",
       "      <td>3.623780</td>\n",
       "      <td>3.701351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.400549</td>\n",
       "      <td>0.731764</td>\n",
       "      <td>2.548001</td>\n",
       "      <td>2.907550</td>\n",
       "      <td>3.467431</td>\n",
       "      <td>3.621517</td>\n",
       "      <td>4.458247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       RMSE                                                    \\\n",
       "                      count      mean       std       min       25%       50%   \n",
       "Model                                                                           \n",
       "SVR                     5.0  2.698487  0.787996  1.907475  2.424237  2.446347   \n",
       "Selected regression     5.0  2.759890  0.737478  2.123133  2.387467  2.414699   \n",
       "Linear Regression       5.0  2.762648  0.789071  2.086587  2.345208  2.452628   \n",
       "XGBoost Regressor       5.0  3.052754  0.646235  2.403523  2.710379  2.859532   \n",
       "Random Forest           5.0  3.059361  0.324533  2.728764  2.837930  2.980707   \n",
       "Polynomial Regression   5.0  3.094362  0.574515  2.585462  2.785954  2.890302   \n",
       "Neural Network          5.0  3.287775  0.607712  2.779042  2.896948  2.903579   \n",
       "Decision Tree           5.0  3.336951  0.367486  2.933887  2.956089  3.469649   \n",
       "XGBoost Classifier      5.0  3.400549  0.731764  2.548001  2.907550  3.467431   \n",
       "\n",
       "                                           \n",
       "                            75%       max  \n",
       "Model                                      \n",
       "SVR                    2.704697  4.009678  \n",
       "Selected regression    2.891632  3.982520  \n",
       "Linear Regression      2.840639  4.088175  \n",
       "XGBoost Regressor      3.202163  4.088175  \n",
       "Random Forest          3.204564  3.544840  \n",
       "Polynomial Regression  3.156190  4.053900  \n",
       "Neural Network         3.712764  4.146541  \n",
       "Decision Tree          3.623780  3.701351  \n",
       "XGBoost Classifier     3.621517  4.458247  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_results_without.groupby(\"Model\").describe().sort_values(by=('RMSE','mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_results_without.groupby(\"Model\").describe().sort_values(by=('RMSE','mean')).to_latex(\"result_without.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "sns.boxplot(data=total_results_without, x=\"Model\", y=\"RMSE\", color=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najlepsze modele teraz użyjemy w komitetach.\n",
    "# Komitety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_with = Pipeline([\n",
    "                    (\"Poly\", poly_with),\n",
    "                    (\"Select\", SelectKBest(f_regression, 26)),\n",
    "                    (\"Linreg\", LinearRegression())\n",
    "])\n",
    "\n",
    "select_with = TransformedTargetRegressor(select_with, inverse_func=convert_to_int)\n",
    "\n",
    "select_without = Pipeline([\n",
    "                    (\"Poly\", poly_without),\n",
    "                    (\"Select\", SelectKBest(f_regression, 26)),\n",
    "                    (\"Linreg\", LinearRegression())\n",
    "])\n",
    "\n",
    "select_without = TransformedTargetRegressor(select_without, inverse_func=convert_to_int)\n",
    "\n",
    "svr_with = TransformedTargetRegressor(\n",
    "    SVR(C=80, gamma='scale', kernel='rbf'),\n",
    "    inverse_func=convert_to_int)\n",
    "\n",
    "svr_without = Pipeline([\n",
    "    (\"Standard Scaler\", StandardScaler()),\n",
    "    (\"SVR\", SVR(C=3, kernel='rbf', gamma='scale'))\n",
    "])\n",
    "\n",
    "svr_without = TransformedTargetRegressor(svr_without, inverse_func = convert_to_int)\n",
    "\n",
    "linreg = TransformedTargetRegressor(LinearRegression(), inverse_func = convert_to_int)\n",
    "\n",
    "\n",
    "ensemble_with = pd.DataFrame(columns=[\"Model\", \"RMSE\"])\n",
    "ensemble_without = pd.DataFrame(columns=[\"Model\", \"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_with = [('Selected Regression', select_with), ('SVR', svr_with), ('Linear Regression', linreg)]\n",
    "estimators_without = [('Selected Regression', select_without), ('SVR', svr_without), ('Linear Regression', linreg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking with exams\n",
      "Average: 1.359\n",
      "Standard deviation: 0.320\n",
      "Stacking without exams\n",
      "Average: 2.730\n",
      "Standard deviation: 0.703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "stacking_with = StackingRegressor(estimators=estimators_with, final_estimator=LinearRegression())\n",
    "stacking_with = TransformedTargetRegressor(stacking_with, inverse_func=convert_to_int)\n",
    "\n",
    "stacking_without = StackingRegressor(estimators=estimators_without, final_estimator=LinearRegression())\n",
    "stacking_without = TransformedTargetRegressor(stacking_without, inverse_func=convert_to_int)\n",
    "\n",
    "result_with = cross_validate(stacking_with, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "ensemble_with = append_to_results(ensemble_with, \"Linear Regression\", result_with.get('test_rmse'))\n",
    "\n",
    "print(\"Stacking with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))\n",
    "\n",
    "result_without = cross_validate(stacking_without, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "ensemble_without = append_to_results(ensemble_without, \"Linear Regression\", result_without.get('test_rmse'))\n",
    "print(\"Stacking without exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking with exams\n",
      "Average: 1.621\n",
      "Standard deviation: 0.760\n",
      "Stacking without exams\n",
      "Average: 2.938\n",
      "Standard deviation: 1.076\n"
     ]
    }
   ],
   "source": [
    "stacking_with = StackingRegressor(estimators=estimators_with, final_estimator=SVR())\n",
    "stacking_with = TransformedTargetRegressor(stacking_with, inverse_func=convert_to_int)\n",
    "\n",
    "stacking_without = StackingRegressor(estimators=estimators_without, final_estimator=SVR())\n",
    "stacking_without = TransformedTargetRegressor(stacking_without, inverse_func=convert_to_int)\n",
    "\n",
    "result_with = cross_validate(stacking_with, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "ensemble_with = append_to_results(ensemble_with, \"SVR\", result_with.get('test_rmse'))\n",
    "\n",
    "print(\"Stacking with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))\n",
    "\n",
    "result_without = cross_validate(stacking_without, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "ensemble_without = append_to_results(ensemble_without, \"SVR\", result_without.get('test_rmse'))\n",
    "\n",
    "print(\"Stacking without exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking with exams\n",
      "Average: 1.438\n",
      "Standard deviation: 0.280\n",
      "Stacking without exams\n",
      "Average: 3.290\n",
      "Standard deviation: 0.790\n"
     ]
    }
   ],
   "source": [
    "stacking_with = StackingRegressor(estimators=estimators_with, final_estimator=XGBRegressor())\n",
    "stacking_with = TransformedTargetRegressor(stacking_with, inverse_func=convert_to_int)\n",
    "\n",
    "stacking_without = StackingRegressor(estimators=estimators_without, final_estimator=XGBRegressor())\n",
    "stacking_without = TransformedTargetRegressor(stacking_without, inverse_func=convert_to_int)\n",
    "\n",
    "result_with = cross_validate(stacking_with, X_with_exams, Y, scoring=metrics, cv=5)\n",
    "ensemble_with = append_to_results(ensemble_with, \"XGB Regressor\", result_with.get('test_rmse'))\n",
    "\n",
    "print(\"Stacking with exams\")\n",
    "avg_sd_print(result_with.get('test_rmse'))\n",
    "\n",
    "result_without = cross_validate(stacking_without, X_without_exams, Y, scoring=metrics, cv=5)\n",
    "ensemble_without = append_to_results(ensemble_without, \"XGB Regressor\", result_without.get('test_rmse'))\n",
    "\n",
    "print(\"Stacking without exams\")\n",
    "avg_sd_print(result_without.get('test_rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.359486</td>\n",
       "      <td>0.357478</td>\n",
       "      <td>1.034036</td>\n",
       "      <td>1.186462</td>\n",
       "      <td>1.196148</td>\n",
       "      <td>1.435806</td>\n",
       "      <td>1.944980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB Regressor</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.438033</td>\n",
       "      <td>0.313587</td>\n",
       "      <td>1.037749</td>\n",
       "      <td>1.218448</td>\n",
       "      <td>1.478044</td>\n",
       "      <td>1.640825</td>\n",
       "      <td>1.815096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.621365</td>\n",
       "      <td>0.849156</td>\n",
       "      <td>1.026570</td>\n",
       "      <td>1.163549</td>\n",
       "      <td>1.400549</td>\n",
       "      <td>1.403293</td>\n",
       "      <td>3.112864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RMSE                                                    \\\n",
       "                  count      mean       std       min       25%       50%   \n",
       "Model                                                                       \n",
       "Linear Regression   5.0  1.359486  0.357478  1.034036  1.186462  1.196148   \n",
       "XGB Regressor       5.0  1.438033  0.313587  1.037749  1.218448  1.478044   \n",
       "SVR                 5.0  1.621365  0.849156  1.026570  1.163549  1.400549   \n",
       "\n",
       "                                       \n",
       "                        75%       max  \n",
       "Model                                  \n",
       "Linear Regression  1.435806  1.944980  \n",
       "XGB Regressor      1.640825  1.815096  \n",
       "SVR                1.403293  3.112864  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_with.groupby(\"Model\").describe().sort_values(by=('RMSE','mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_with.groupby(\"Model\").describe().sort_values(by=('RMSE','mean')).to_latex(\"ensemble_with.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "sns.boxplot(data=ensemble_with, x=\"Model\", y=\"RMSE\", color=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.730226</td>\n",
       "      <td>0.785716</td>\n",
       "      <td>1.978733</td>\n",
       "      <td>2.379399</td>\n",
       "      <td>2.428992</td>\n",
       "      <td>2.837930</td>\n",
       "      <td>4.026078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.938258</td>\n",
       "      <td>1.203111</td>\n",
       "      <td>2.009592</td>\n",
       "      <td>2.390687</td>\n",
       "      <td>2.506914</td>\n",
       "      <td>2.747026</td>\n",
       "      <td>5.037072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB Regressor</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.290061</td>\n",
       "      <td>0.882723</td>\n",
       "      <td>2.189134</td>\n",
       "      <td>2.561550</td>\n",
       "      <td>3.536622</td>\n",
       "      <td>3.907586</td>\n",
       "      <td>4.255412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RMSE                                                    \\\n",
       "                  count      mean       std       min       25%       50%   \n",
       "Model                                                                       \n",
       "Linear Regression   5.0  2.730226  0.785716  1.978733  2.379399  2.428992   \n",
       "SVR                 5.0  2.938258  1.203111  2.009592  2.390687  2.506914   \n",
       "XGB Regressor       5.0  3.290061  0.882723  2.189134  2.561550  3.536622   \n",
       "\n",
       "                                       \n",
       "                        75%       max  \n",
       "Model                                  \n",
       "Linear Regression  2.837930  4.026078  \n",
       "SVR                2.747026  5.037072  \n",
       "XGB Regressor      3.907586  4.255412  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_without.groupby(\"Model\").describe().sort_values(by=('RMSE','mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_without.groupby(\"Model\").describe().sort_values(by=('RMSE','mean')).to_latex(\"ensemble_without.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "sns.boxplot(data=ensemble_without, x=\"Model\", y=\"RMSE\", color=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Komitety nie poprawiły :(."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
