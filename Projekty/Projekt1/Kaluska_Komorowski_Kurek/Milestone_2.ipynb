{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extended-visit",
   "metadata": {},
   "source": [
    "# Inżynieria cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "better-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-knight",
   "metadata": {},
   "source": [
    "## Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stupid-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"census_income_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-correlation",
   "metadata": {},
   "source": [
    "Z ramki danych zostają usunięte wszystkie wiersze zawierające wartość `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "angry-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({\"?\": np.nan}).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-angel",
   "metadata": {},
   "source": [
    "## Kolumny do usunięcia\n",
    "- `fnlwgt` -> cecha nie wpływa w żaden sposób na podział danych, więc z niej rezygnujemy.\n",
    "- `education` oraz `education_num` -> po przetestowaniu różnych kombinacji grupowania zdecydowaliśmy, że najlepszą opcją jest zrezygowanie z kolumny `education` i zostawienie `education_num` bez żadnych modyfikacji.\n",
    "- `race` -> duża dysproporcja danych, więc pomijamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "academic-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = [\"fnlwgt\", \"education\", \"race\"]\n",
    "df.drop(features_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-overview",
   "metadata": {},
   "source": [
    "### `hours_per_week` \n",
    "pogrupowanie rekordów w trzy kategorie względem wartości `40.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "empty-income",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exactly_40      21358\n",
       "less_than_40    13777\n",
       "more_than_40    10087\n",
       "Name: hours_per_week, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hpw_encode(x):\n",
    "    if x < 40:\n",
    "        return \"more_than_40\"\n",
    "    elif x > 40:\n",
    "        return \"less_than_40\"\n",
    "    else:\n",
    "        return \"exactly_40\"\n",
    "\n",
    "df.hours_per_week = df.hours_per_week.apply(hpw_encode)\n",
    "df.hours_per_week.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-cleaning",
   "metadata": {},
   "source": [
    "### `age`\n",
    "Normalizacja kulumny  przy użyciu `MinMaxScaler()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "confidential-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[\"age\"] = scaler.fit_transform(df[[\"age\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-executive",
   "metadata": {},
   "source": [
    "### `native_country`\n",
    "W tej kolumnie mamy 41 kategorii i oprócz USA, dla każdego państwa mamy bardzo mało obserwacji.\n",
    "Poniżej państwa zostały zgrupowane według kontynetów. USA zostały jako oddzielna kategoria.\n",
    "\n",
    "Wśród państw zostało wyodrębnione 5 kategorii.\n",
    "- United States - Stany Zjednoczone\n",
    "- LA - Ameryka Łacińska - zawiera Outlying-US\n",
    "- ASIA - Azja\n",
    "- EU - Europa\n",
    "- NA - Ameryka Północna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "independent-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_dict = {'United-States': 'United States', \n",
    " 'Cuba': 'LA',\n",
    " 'Jamaica': 'LA',\n",
    " 'South': 'ASIA',\n",
    " 'Mexico': 'LA',\n",
    " 'Puerto-Rico': 'LA',\n",
    " 'Honduras': 'LA',\n",
    " 'England': 'EU',\n",
    " 'Canada': 'NA',\n",
    " 'Germany': 'EU',\n",
    " 'Iran': 'ASIA',\n",
    " 'Philippines': 'ASIA',\n",
    " 'Poland': 'EU',\n",
    " 'Columbia': 'LA',\n",
    " 'Cambodia': 'ASIA',\n",
    " 'Thailand': 'ASIA',\n",
    " 'Ecuador': 'LA',\n",
    " 'Laos': 'ASIA',\n",
    " 'Taiwan': 'ASIA',\n",
    " 'Haiti': 'LA',\n",
    " 'Portugal': 'EU',\n",
    " 'Dominican-Republic': 'LA',\n",
    " 'El-Salvador': 'LA',\n",
    " 'France': 'EU',\n",
    " 'Guatemala': 'LA',\n",
    " 'Italy': 'EU',\n",
    " 'China': 'ASIA',\n",
    " 'India': 'ASIA',\n",
    " 'Japan': 'ASIA',\n",
    " 'Yugoslavia': 'EU',\n",
    " 'Peru': 'LA',\n",
    " 'Hong': 'LA',\n",
    " 'Ireland': 'EU',\n",
    " 'Trinadad&Tobago': 'LA',\n",
    " 'Greece': 'EU',\n",
    " 'Nicaragua': 'LA',\n",
    " 'Vietnam': 'ASIA',\n",
    " 'Outlying-US(Guam-USVI-etc)': 'LA',\n",
    " 'Scotland': 'EU',\n",
    " 'Hungary': 'EU',\n",
    " 'Holand-Netherlands': 'EU'}\n",
    "\n",
    "df[\"native_country\"] = df[\"native_country\"].replace(countries_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-feelings",
   "metadata": {},
   "source": [
    "### `Income level`\n",
    "Zamiana wartości w kolumnie na 0 i 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "raised-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != \"income_level\"]\n",
    "y = df.income_level\n",
    "\n",
    "y = y.apply(lambda x: 1 if x == \">50K\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-crime",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "Kolumny przekształcone za pomocą `OneHotEncoder()`:\n",
    "- `marital_status`\n",
    "- `occupation`\n",
    "-`relationship`\n",
    "- `workclass`\n",
    "-`hours per week` (3 kategorie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sealed-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(use_cat_names=True)\n",
    "X = ohe.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "controlling-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-poetry",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "retained-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = [\"recall\", \"accuracy\", \"roc auc\", \"f1\"]\n",
    "t = pd.DataFrame(columns = indicators) \n",
    "\n",
    "def print_results(name, res_):\n",
    "    print(name, 'accuracy score: {0:0.4f}'. format(np.mean(res_[\"test_accuracy\"])))\n",
    "    print(name, 'recall score: {0:0.4f}'. format(np.mean(res_[\"test_recall\"])))\n",
    "    print(name, 'roc_auc score: {0:0.4f}'. format(np.mean(res_[\"test_roc_auc\"])))\n",
    "    print(name, 'f1 score: {0:0.4f}'. format(np.mean(res_[\"test_f1\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-smart",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "employed-hungary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score: 0.7897\n",
      "Logistic Regression recall score: 0.2637\n",
      "Logistic Regression roc_auc score: 0.6172\n",
      "Logistic Regression f1 score: 0.3834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "y_hat = lr.predict(X_test)\n",
    "res_lr = cross_validate(LogisticRegression(max_iter=1000), X, y, cv=5, scoring=['recall', 'accuracy', 'roc_auc', 'f1'])\n",
    "t.loc[\"Logistic Regression\"] = [np.mean(res_lr[\"test_recall\"]), np.mean(res_lr[\"test_accuracy\"]), np.mean(res_lr[\"test_roc_auc\"]), np.mean(res_lr[\"test_f1\"])]\n",
    "sorted(res_lr.keys())\n",
    "\n",
    "print_results(\"Logistic Regression\", res_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-yukon",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "chubby-taiwan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy score: 0.8449\n",
      "Random Forest recall score: 0.5027\n",
      "Random Forest roc_auc score: 0.9022\n",
      "Random Forest f1 score: 0.6164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=750, max_depth=4).fit(X_train, y_train)\n",
    "\n",
    "y_hat = rf.predict(X_test)\n",
    "res = cross_validate(RandomForestClassifier(n_estimators=1000, max_depth=6), X, y, cv=5, scoring=['recall', 'accuracy', 'roc_auc', 'f1'])\n",
    "t.loc[\"Random Forest\"] = [np.mean(res[\"test_recall\"]), np.mean(res[\"test_accuracy\"]), np.mean(res[\"test_roc_auc\"]), np.mean(res[\"test_f1\"])]\n",
    "\n",
    "print_results(\"Random Forest\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-beast",
   "metadata": {},
   "source": [
    "#### Voting Classifier\n",
    "Logistic Regression & Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "heavy-cooling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier accuracy score: 0.8106\n",
      "Voting Classifier recall score: 0.3047\n",
      "Voting Classifier roc_auc score: 0.8341\n",
      "Voting Classifier f1 score: 0.4350\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "model_soft = VotingClassifier(estimators=[('RandomForest', rf), ('LR', lr)], voting='soft', weights=[0.4, 0.6])\n",
    "\n",
    "res_ms = cross_validate(model_soft, X_train, y_train, cv=5, scoring=['recall', 'accuracy', 'roc_auc', 'f1'])\n",
    "t.loc[\"Voting Classifier\"] = [np.mean(res_ms[\"test_recall\"]), np.mean(res_ms[\"test_accuracy\"]), np.mean(res_ms[\"test_roc_auc\"]), np.mean(res_ms[\"test_f1\"])]\n",
    "\n",
    "print_results(\"Voting Classifier\",res_ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-entrepreneur",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "incorrect-lawyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost accuracy score: 0.8688\n",
      "AdaBoost recall score: 0.6500\n",
      "AdaBoost roc_auc score: 0.9263\n",
      "AdaBoost f1 score: 0.7106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=1000)\n",
    "\n",
    "res = cross_validate(AdaBoostClassifier(n_estimators=1000), X, y, cv=5, scoring=['recall', 'accuracy', 'roc_auc', 'f1'])\n",
    "t.loc[\"AdaBoost\"] = [np.mean(res[\"test_recall\"]), np.mean(res[\"test_accuracy\"]), np.mean(res[\"test_roc_auc\"]), np.mean(res[\"test_f1\"])]\n",
    "\n",
    "print_results(\"AdaBoost\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-immigration",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "revised-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost accuracy score: 0.8709\n",
      "CatBoost recall score: 0.6571\n",
      "CatBoost roc_auc score: 0.9286\n",
      "CatBoost f1 score: 0.7162\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "catb = CatBoostClassifier(verbose=False, learning_rate=0.04, depth=6)\n",
    "\n",
    "res = cross_validate(CatBoostClassifier(verbose=False, learning_rate=0.04, depth=6), X, y, cv=5, scoring=['recall', 'accuracy', 'roc_auc', 'f1'])\n",
    "t.loc[\"CatBoost\"] = [np.mean(res[\"test_recall\"]), np.mean(res[\"test_accuracy\"]), np.mean(res[\"test_roc_auc\"]), np.mean(res[\"test_f1\"])]\n",
    "\n",
    "print_results(\"CatBoost\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-jerusalem",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "celtic-hybrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting accuracy score: 0.8698\n",
      "Gradient Boosting recall score: 0.6528\n",
      "Gradient Boosting roc_auc score: 0.9266\n",
      "Gradient Boosting f1 score: 0.7128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model2 = GradientBoostingClassifier(random_state=1,\n",
    "                                  learning_rate=0.3)\n",
    "\n",
    "res_m = cross_validate(model2, X_train, y_train, cv=5, scoring=['recall','accuracy', 'roc_auc', 'f1'])\n",
    "t.loc[\"Gradient Boosting\"] = [np.mean(res_m[\"test_recall\"]), np.mean(res_m[\"test_accuracy\"]), np.mean(res_m[\"test_roc_auc\"]), np.mean(res_m[\"test_f1\"])]\n",
    "\n",
    "print_results(\"Gradient Boosting\" ,res_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-smooth",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "anticipated-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy score: 0.8659\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier \n",
    "\n",
    "xg_boost=XGBClassifier(random_state=1,\n",
    "                    learning_rate=0.4, # Szybkość \"uczenia\" się\n",
    "                    booster='gbtree', # Jaki model wykorzystujemy (drzewo - gbtree, liniowe - gblinear)\n",
    "                    max_depth=4, # Maksymalna głębokość drzewa \n",
    "                    eval_metric=\"logloss\",\n",
    "                    use_label_encoder=False)\n",
    "\n",
    "xg_boost.fit(X_train, y_train)\n",
    "y_hat = xg_boost.predict(X_test)\n",
    "print(\"XGBoost accuracy score: {0:0.4f}\". format(accuracy_score(y_test, y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "breeding-amber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy score: 0.8711\n",
      "XGBoost recall score: 0.6650\n",
      "XGBoost roc_auc score: 0.9279\n",
      "XGBoost f1 score: 0.7185\n"
     ]
    }
   ],
   "source": [
    "res = cross_validate(xg_boost, X_train, y_train, cv=5, scoring=['recall', 'accuracy', 'roc_auc', 'f1'])\n",
    "t.loc[\"XGBoost\"] = [np.mean(res[\"test_recall\"]), np.mean(res[\"test_accuracy\"]), np.mean(res[\"test_roc_auc\"]), np.mean(res[\"test_f1\"])]\n",
    "\n",
    "print_results(\"XGBoost\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-milwaukee",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Podsumowanie wyników względem miary `roc auc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "racial-excitement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc auc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.657120</td>\n",
       "      <td>0.870926</td>\n",
       "      <td>0.928584</td>\n",
       "      <td>0.716182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.665039</td>\n",
       "      <td>0.871064</td>\n",
       "      <td>0.927872</td>\n",
       "      <td>0.718521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.646949</td>\n",
       "      <td>0.868560</td>\n",
       "      <td>0.926875</td>\n",
       "      <td>0.709269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.652770</td>\n",
       "      <td>0.869825</td>\n",
       "      <td>0.926582</td>\n",
       "      <td>0.712818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting Classifier</th>\n",
       "      <td>0.560572</td>\n",
       "      <td>0.850543</td>\n",
       "      <td>0.906167</td>\n",
       "      <td>0.649907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.606086</td>\n",
       "      <td>0.848326</td>\n",
       "      <td>0.903777</td>\n",
       "      <td>0.664510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.507762</td>\n",
       "      <td>0.849299</td>\n",
       "      <td>0.902889</td>\n",
       "      <td>0.625517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       recall  accuracy   roc auc        f1\n",
       "CatBoost             0.657120  0.870926  0.928584  0.716182\n",
       "XGBoost              0.665039  0.871064  0.927872  0.718521\n",
       "AdaBoost             0.646949  0.868560  0.926875  0.709269\n",
       "Gradient Boosting    0.652770  0.869825  0.926582  0.712818\n",
       "Voting Classifier    0.560572  0.850543  0.906167  0.649907\n",
       "Logistic Regression  0.606086  0.848326  0.903777  0.664510\n",
       "Random Forest        0.507762  0.849299  0.902889  0.625517"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sort_values(by = 'roc auc', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-blues",
   "metadata": {},
   "source": [
    "Najwyższą jakość klasyfikacji uzyskały modele **CatBoost** oraz **XGBoost**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
