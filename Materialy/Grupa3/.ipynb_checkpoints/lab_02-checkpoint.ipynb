{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pakiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.datasets import load_boston\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zbiór danych nt. butów męskich\n",
    "## naszym celem jest przewidzenie ceny - prices_amountmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patryk\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (29) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>colors</th>\n",
       "      <th>count</th>\n",
       "      <th>dateadded</th>\n",
       "      <th>dateupdated</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>prices_warranty</th>\n",
       "      <th>quantities</th>\n",
       "      <th>reviews</th>\n",
       "      <th>sizes</th>\n",
       "      <th>skus</th>\n",
       "      <th>sourceurls</th>\n",
       "      <th>upc</th>\n",
       "      <th>vin</th>\n",
       "      <th>websiteids</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVpfHrJ6ilAPnD_xVXOI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Josmo</td>\n",
       "      <td>Clothing,Shoes,Men's Shoes,All Men's Shoes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-07T00:45:12Z</td>\n",
       "      <td>2016-11-07T00:45:12Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2016-11-07T00:45:12Z\"],\"sourceU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.walmart.com/ip/Josmo-8190-Plain-In...</td>\n",
       "      <td>6.993020e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVpfHrJ6ilAPnD_xVXOI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Josmo</td>\n",
       "      <td>Clothing,Shoes,Men's Shoes,All Men's Shoes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-07T00:45:12Z</td>\n",
       "      <td>2016-11-07T00:45:12Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2016-11-07T00:45:12Z\"],\"sourceU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.walmart.com/ip/Josmo-8190-Plain-In...</td>\n",
       "      <td>6.993020e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVpfHsWP1cnluZ0-eVZ7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SERVUS BY HONEYWELL</td>\n",
       "      <td>All Men's Shoes,Shoes,Men's Shoes,Clothing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-14T04:29:57Z</td>\n",
       "      <td>2016-07-09T20:26:48Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2016-07-09T20:26:48Z\"],\"sourceU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.walmart.com/ip/Studs-Shoe-Large-Pr-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVpfHsWP1cnluZ0-eVZ7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SERVUS BY HONEYWELL</td>\n",
       "      <td>All Men's Shoes,Shoes,Men's Shoes,Clothing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-14T04:29:57Z</td>\n",
       "      <td>2016-07-09T20:26:48Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2016-07-09T20:26:48Z\"],\"sourceU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.walmart.com/ip/Studs-Shoe-Large-Pr-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVpfHsWP1cnluZ0-eVZ7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SERVUS BY HONEYWELL</td>\n",
       "      <td>All Men's Shoes,Shoes,Men's Shoes,Clothing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-14T04:29:57Z</td>\n",
       "      <td>2016-07-09T20:26:48Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2016-07-09T20:26:48Z\"],\"sourceU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.walmart.com/ip/Studs-Shoe-Large-Pr-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id asins                brand  \\\n",
       "0  AVpfHrJ6ilAPnD_xVXOI   NaN                Josmo   \n",
       "1  AVpfHrJ6ilAPnD_xVXOI   NaN                Josmo   \n",
       "2  AVpfHsWP1cnluZ0-eVZ7   NaN  SERVUS BY HONEYWELL   \n",
       "3  AVpfHsWP1cnluZ0-eVZ7   NaN  SERVUS BY HONEYWELL   \n",
       "4  AVpfHsWP1cnluZ0-eVZ7   NaN  SERVUS BY HONEYWELL   \n",
       "\n",
       "                                   categories colors  count  \\\n",
       "0  Clothing,Shoes,Men's Shoes,All Men's Shoes    NaN    NaN   \n",
       "1  Clothing,Shoes,Men's Shoes,All Men's Shoes    NaN    NaN   \n",
       "2  All Men's Shoes,Shoes,Men's Shoes,Clothing    NaN    NaN   \n",
       "3  All Men's Shoes,Shoes,Men's Shoes,Clothing    NaN    NaN   \n",
       "4  All Men's Shoes,Shoes,Men's Shoes,Clothing    NaN    NaN   \n",
       "\n",
       "              dateadded           dateupdated  \\\n",
       "0  2016-11-07T00:45:12Z  2016-11-07T00:45:12Z   \n",
       "1  2016-11-07T00:45:12Z  2016-11-07T00:45:12Z   \n",
       "2  2016-06-14T04:29:57Z  2016-07-09T20:26:48Z   \n",
       "3  2016-06-14T04:29:57Z  2016-07-09T20:26:48Z   \n",
       "4  2016-06-14T04:29:57Z  2016-07-09T20:26:48Z   \n",
       "\n",
       "                                        descriptions dimension  ...  \\\n",
       "0  [{\"dateSeen\":[\"2016-11-07T00:45:12Z\"],\"sourceU...       NaN  ...   \n",
       "1  [{\"dateSeen\":[\"2016-11-07T00:45:12Z\"],\"sourceU...       NaN  ...   \n",
       "2  [{\"dateSeen\":[\"2016-07-09T20:26:48Z\"],\"sourceU...       NaN  ...   \n",
       "3  [{\"dateSeen\":[\"2016-07-09T20:26:48Z\"],\"sourceU...       NaN  ...   \n",
       "4  [{\"dateSeen\":[\"2016-07-09T20:26:48Z\"],\"sourceU...       NaN  ...   \n",
       "\n",
       "   prices_warranty quantities  reviews sizes  skus  \\\n",
       "0              NaN        NaN      NaN   NaN   NaN   \n",
       "1              NaN        NaN      NaN   NaN   NaN   \n",
       "2              NaN        NaN      NaN   NaN   NaN   \n",
       "3              NaN        NaN      NaN   NaN   NaN   \n",
       "4              NaN        NaN      NaN   NaN   NaN   \n",
       "\n",
       "                                          sourceurls           upc vin  \\\n",
       "0  https://www.walmart.com/ip/Josmo-8190-Plain-In...  6.993020e+11 NaN   \n",
       "1  https://www.walmart.com/ip/Josmo-8190-Plain-In...  6.993020e+11 NaN   \n",
       "2  http://www.walmart.com/ip/Studs-Shoe-Large-Pr-...           NaN NaN   \n",
       "3  http://www.walmart.com/ip/Studs-Shoe-Large-Pr-...           NaN NaN   \n",
       "4  http://www.walmart.com/ip/Studs-Shoe-Large-Pr-...           NaN NaN   \n",
       "\n",
       "  websiteids weight  \n",
       "0        NaN    NaN  \n",
       "1        NaN    NaN  \n",
       "2        NaN    NaN  \n",
       "3        NaN    NaN  \n",
       "4        NaN    NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wczytujemy dane \n",
    "shoes_df = pd.read_csv('menshoes.csv')\n",
    "\n",
    "# w tym momencie następuje odruch bezwarunkowy\n",
    "shoes_df.head()\n",
    "\n",
    "# jakie wnioski?\n",
    "# @conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18280 entries, 0 to 18279\n",
      "Data columns (total 48 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   18280 non-null  object \n",
      " 1   asins                2161 non-null   object \n",
      " 2   brand                18263 non-null  object \n",
      " 3   categories           18280 non-null  object \n",
      " 4   colors               10344 non-null  object \n",
      " 5   count                0 non-null      float64\n",
      " 6   dateadded            18280 non-null  object \n",
      " 7   dateupdated          18280 non-null  object \n",
      " 8   descriptions         9704 non-null   object \n",
      " 9   dimension            2968 non-null   object \n",
      " 10  ean                  9690 non-null   float64\n",
      " 11  features             13299 non-null  object \n",
      " 12  flavors              0 non-null      float64\n",
      " 13  imageurls            17255 non-null  object \n",
      " 14  isbn                 0 non-null      float64\n",
      " 15  keys                 18280 non-null  object \n",
      " 16  manufacturer         6296 non-null   object \n",
      " 17  manufacturernumber   14309 non-null  object \n",
      " 18  merchants            13018 non-null  object \n",
      " 19  name                 18280 non-null  object \n",
      " 20  prices_amountmin     18280 non-null  float64\n",
      " 21  prices_amountmax     18280 non-null  float64\n",
      " 22  prices_availability  114 non-null    object \n",
      " 23  prices_color         558 non-null    object \n",
      " 24  prices_condition     11675 non-null  object \n",
      " 25  prices_count         0 non-null      float64\n",
      " 26  prices_currency      18280 non-null  object \n",
      " 27  prices_dateadded     18280 non-null  object \n",
      " 28  prices_dateseen      18280 non-null  object \n",
      " 29  prices_flavor        1 non-null      object \n",
      " 30  prices_issale        18280 non-null  bool   \n",
      " 31  prices_merchant      13160 non-null  object \n",
      " 32  prices_offer         5874 non-null   object \n",
      " 33  prices_returnpolicy  798 non-null    object \n",
      " 34  prices_shipping      4906 non-null   object \n",
      " 35  prices_size          486 non-null    object \n",
      " 36  prices_source        0 non-null      float64\n",
      " 37  prices_sourceurls    18265 non-null  object \n",
      " 38  prices_warranty      42 non-null     object \n",
      " 39  quantities           0 non-null      float64\n",
      " 40  reviews              1592 non-null   object \n",
      " 41  sizes                5920 non-null   object \n",
      " 42  skus                 8120 non-null   object \n",
      " 43  sourceurls           18246 non-null  object \n",
      " 44  upc                  10488 non-null  float64\n",
      " 45  vin                  0 non-null      float64\n",
      " 46  websiteids           0 non-null      float64\n",
      " 47  weight               570 non-null    object \n",
      "dtypes: bool(1), float64(12), object(35)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#  Korzystając z przyjaciół przyjrzyjmy się bliżej\n",
    "shoes_df.info()\n",
    "# @conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = shoes_df.shape[0] * 0.7\n",
    "shoes_df_drop = shoes_df.loc[:, shoes_df.apply(lambda x: x.isna().sum(), axis=0) < threshold]\n",
    "shoes_df_drop.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "które kolumny jeszcze wydają się niepotrzebne?  \n",
    "które kolumny trzeba przekształcić?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# popatrzmy na kolory butów\n",
    "shoes_df_drop['colors'].value_counts()\n",
    "\n",
    "# jakie jest ograniczenie metody .value_counts()?\n",
    "# @conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wartości NA\n",
    "pd.DataFrame(shoes_df_drop['colors']).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jest sporo braków  \n",
    "pomówimy jak z tym żyć za chwilę  \n",
    "najpierw wizualizacja  \n",
    "jakieś pomysły na wizualizację zmienna ciągła vs. kategoryczna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Black_Brown = shoes_df_drop.loc[shoes_df_drop['colors'].isin(['Black', 'Brown'])]\n",
    "violin_plot = sns.violinplot(Black_Brown['colors'], Black_Brown['prices_amountmin'])\n",
    "violin_plot.set_title('Rozkład ceny względem koloru butów')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_colors=shoes_df_drop.loc[shoes_df_drop['colors'].isin(shoes_df_drop['colors'].value_counts().index[:5])]\n",
    "mean_price_popular_colors=popular_colors.groupby('colors')['prices_amountmin'].mean()\n",
    "mean_price_popular_colors.plot(kind='bar', title='Średnia cena')\n",
    "plt.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputacja zmiennych kategorycznych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kolumna colors miała dużo nieuzupełnionych wartości  \n",
    "jak można je uzupełnić?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# możnaby najczęściej występującym kolorem, ale czy to nie wprowadza fałszywej informacji?\n",
    "# lepsze podejście - nowa klasa 'Other'\n",
    "shoes_df_drop['colors'].fillna('Missing_color')  #działa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# czy można lepiej?\n",
    "# można!\n",
    "shoes_df_drop['missing' + 'colors'] = shoes_df_drop['colors'].isna()*1\n",
    "shoes_df_drop['colors'].fillna('Missing_color', inplace=True)\n",
    "\n",
    "# po co ta informacja, skoro w kolumnie już jest napisane, że to brakujący kolor?\n",
    "# @conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uwaga, to co jest wyżej to wcale nie jest prawda  \n",
    "### przekonamy się o tym przy one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputacja zmiennych ciągłych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w naszym zbiorze nie ma nic do imputacji ciągłej\n",
    "# zerknijmy na szutczny zbiór\n",
    "fake_data=pd.DataFrame({'num':np.random.choice([None, 3,4], 100), \n",
    "                        'cat': np.random.choice([None, 'Puma','Nike','Adidas'], 100, p=[0.92, 0.03, 0.03, 0.02])})\n",
    "fake_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# średnia czy mediana?\n",
    "fake_data.num.fillna(fake_data.num.median(), inplace=True) #fake_data.num.mean()\n",
    "fake_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dane jedynie z przedziału (średnia +- 3 sigma) - ma to sens gdy rozkład normalny\n",
    "data=pd.DataFrame({'num':np.random.normal(2,0.4,1000)})\n",
    "factor = 3\n",
    "upper_lim = data['num'].mean () + data['num'].std () * factor\n",
    "lower_lim = data['num'].mean () - data['num'].std () * factor\n",
    "\n",
    "data = data[(data['num'] < upper_lim) & (data['num'] > lower_lim)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwanie na podstawie skrajnych percentyli\n",
    "# to już zadziała \"dobrze\" dla każdego rozkładu\n",
    "# załadujmy nasz ulubiony Boston\n",
    "boston_dict = load_boston()\n",
    "boston_df = pd.DataFrame(boston_dict['data'], columns=boston_dict['feature_names'])\n",
    "\n",
    "dis_data = boston_df['DIS']\n",
    "print('Wejściowy rozmiar: ', dis_data.shape[0])\n",
    "\n",
    "upper_lim = dis_data.quantile(.95)\n",
    "lower_lim = dis_data.quantile(.05)\n",
    "\n",
    "data_percentile = dis_data[(dis_data < upper_lim) & (dis_data > lower_lim)]\n",
    "print('Wyjściowy rozmiar: ', data_percentile.shape[0])\n",
    "print('Pozostało %: ', round(data_percentile.shape[0]/dis_data.shape[0], 2))\n",
    "\n",
    "# co tu jest nie halo?\n",
    "# @conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to może boxplot?\n",
    "# faktycznie, dołu nie powinniśmy obcinać\n",
    "# ale na górze są outliery!\n",
    "plot_box = sns.boxplot(boston_df['DIS'])\n",
    "plot_box.set_title('Rozkład zmiennej DIS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nope\n",
    "# ten rozkład taki jest, nie można go za to winić\n",
    "# tu nie ma outlierów\n",
    "plot_dens=sns.histplot(boston_df['DIS'])\n",
    "plot_dens.set_title('Rozkład zmiennej DIS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Grouping & Binning\n",
    "### Agregujemy klasy do wyższego poziomu lub tniemy zmienną ciągłą na klasy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "czasami potrzebujemy zrobić ze zmiennej ciągłej kategoryczną  \n",
    "albo mamy zmienną kategoryczną o bardzo dużej liczbie klas  \n",
    "albo dużo klas mało licznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zobaczmy jak wygląda kolumna brand \n",
    "shoes_df_drop['brand'].value_counts()\n",
    "# co można z tym zrobić?\n",
    "# @conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jest aż 560 marek, które występują raz\n",
    "shoes_df_drop['brand'].value_counts()[shoes_df_drop['brand'].value_counts() == 1].shape[0]\n",
    "\n",
    "# czyli grupujemy w kategorię Other?\n",
    "# @conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przyjrzyjmy się bliżej\n",
    "brands = shoes_df_drop[['brand']].groupby(['brand']).size().sort_values(ascending=False).reset_index()\n",
    "brands.columns = ['brand', 'count']\n",
    "brands.loc[brands['brand'].apply(lambda x:'nike' in x.lower())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "może warto najpierw zgrupować Najacze a potem dopiero Others?  \n",
    "Nike i NIKE to na pewno to samo, ale może NIKE - Kobe to dość niszowe obuwie i warto, żeby było Others?  \n",
    "to samodzielna decyzja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nike_synonyms = brands.loc[brands['brand'].apply(lambda x:'nike' in x.lower()), 'brand'].values\n",
    "\n",
    "small_classes = shoes_df_drop['brand'].value_counts()[shoes_df_drop['brand'].value_counts() == 1].index\n",
    "\n",
    "shoes_df_drop['brands' + '_processed'] = np.where(shoes_df_drop['brand'].isin(nike_synonyms), 'nike', \n",
    "                                              np.where(shoes_df_drop['brand'].isin(small_classes), 'Other', shoes_df_drop['brand']))\n",
    "\n",
    "shoes_df_drop['brands' + '_processed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# można to zrobić też przy pomocy słownika\n",
    "geo=np.random.choice((\"Poland\",'Chile', 'France', 'Spain'), 100)\n",
    "geo=pd.Series(geo)\n",
    "geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_geo={'Poland': \"Europe\", \"Chile\":\"South America\", \"France\":\"Europe\"}\n",
    "from collections import defaultdict\n",
    "countries_list = [('Poland','Europe'), ('France','Europe'), ('Chile','South America')]\n",
    "geo.map(dict_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metoda z użyciem dict/defaultdict\n",
    "countries_dict = defaultdict(lambda:'Other')\n",
    "for continent, country in countries_list:\n",
    "     countries_dict[continent]=country\n",
    "geo.map(countries_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naszym celem było przewidywanie cen butów\n",
    "# ale może wystarczy jeśli przewidzimy to bardziej z grubsza? Tanie, średnie, drogie\n",
    "prices_hist = sns.histplot(shoes_df_drop['prices_amountmin'])\n",
    "prices_hist.set_title('Rozkład cen butów')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(shoes_df_drop['prices_amountmin'], bins=[0, 100, 200, 250], labels=['cheap', 'affordable', 'expensive'])[17:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutted = pd.cut(shoes_df_drop['prices_amountmin'], bins=[0, 100, 200, np.inf], labels=['cheap', 'affordable', 'expensive'])\n",
    "cutted[18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zawsze warto sprawdzić\n",
    "cutted[cutted.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i spróbować zrozumieć dlaczego\n",
    "shoes_df_drop.loc[4176, 'prices_amountmin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dla przypomnienia - Log Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_dist = sns.distplot(boston_df['DIS'])\n",
    "dis_dist.set_title('Rozkład zmiennej DIS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_log_dist = sns.distplot(np.log1p(boston_df['DIS']))\n",
    "dis_log_dist.set_title('Rozkład logarytmu zmiennej DIS')\n",
    "plt.show()\n",
    "# nie jest idealnie, ale na pewno mniej skośnie \\:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical variables encoding\n",
    "### algorytmy często nie lubią zmiennych kategorycznych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 1 1 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "values = np.array(data)\n",
    "\n",
    "# integer encode\n",
    "le = LabelEncoder()\n",
    "integer_encoded = le.fit_transform(values)\n",
    "print(integer_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warto zauważyć, że to ma sens, tylko dla zmiennych, które reprezentują jakieś poziomy/kolejność"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 0 1 1 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "# uwaga! \n",
    "# nie panujemy nad kolejnością -> check OrdinalEncoder\n",
    "data = ['hot', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
    "values = np.array(data)\n",
    "le = LabelEncoder()\n",
    "integer_encoded = le.fit_transform(values)\n",
    "print(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# przykład z naszych danych\n",
    "# kolumna categories wyglądała obiecująco\n",
    "shoes_df_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_df_drop['categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podrążmy temat\n",
    "categories = {}\n",
    "def split_and_count(x, categories):\n",
    "    cat_list = x.split(',')\n",
    "    for cat in cat_list:\n",
    "        categories.setdefault(cat, 0)\n",
    "        categories[cat] += 1\n",
    "    return categories\n",
    "\n",
    "for row in shoes_df_drop['categories'].iteritems():\n",
    "    split_and_count(row[1], categories)\n",
    "categories_df = pd.DataFrame.from_dict(categories, orient='index').reset_index()\n",
    "categories_df.columns = ['category', 'count']\n",
    "categories_df.sort_values(by='count', ascending=False).head(20)\n",
    "\n",
    "# kategorie typu athletic, *sport, *outwear mogą się nadawać na one-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "- min-max scaling\n",
    "- standarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "niektóre algorytmy nie lubią dużych skal zmiennych - regresja liniowa z poprzednich zajęć   \n",
    "jakiś parametr musi \"obsłużyć\" bardzo małe i bardzo duże liczby  \n",
    "inne potrzebują mieć zmienne w konkretnym przedziale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# min-max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = np.array([-1, 2, -0.5, 6, 0, 10, 1, 18]).reshape(-1, 1)\n",
    "mm_scaler = MinMaxScaler()\n",
    "\n",
    "print(mm_scaler.fit_transform(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = np.array([-1, 2, -0.5, 6, 0, 10, 1, 18]).reshape(-1, 1)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(scaled_data)\n",
    "print(np.round(np.mean(scaled_data), 4), np.std(scaled_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting info from date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "data = pd.DataFrame({'date':\n",
    "['01-01-2017',\n",
    "'04-12-2008',\n",
    "'23-06-1988',\n",
    "'25-08-1999',\n",
    "'20-02-1993',\n",
    "]})\n",
    "\n",
    "#Transform string to date\n",
    "data['date'] = pd.to_datetime(data.date, format=\"%d-%m-%Y\")\n",
    "\n",
    "#Extracting Year\n",
    "data['year'] = data['date'].dt.year\n",
    "\n",
    "#Extracting Month\n",
    "data['month'] = data['date'].dt.month\n",
    "\n",
    "#Extracting passed years since the date\n",
    "data['passed_years'] = date.today().year - data['date'].dt.year\n",
    "\n",
    "#Extracting passed months since the date\n",
    "data['passed_months'] = (date.today().year - data['date'].dt.year) * 12 + date.today().month - data['date'].dt.month\n",
    "\n",
    "#Extracting the weekday name of the date\n",
    "data['day_name'] = data['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# warto poczytać\n",
    "pakiet category_encoders:\n",
    "- https://kiwidamien.github.io/encoding-categorical-variables.html\n",
    "- https://pbpython.com/categorical-encoding.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciekawa strona z przykładami wizualizacji (wraz z kodem):\n",
    "    https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
