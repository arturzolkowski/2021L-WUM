{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja \n",
    "Klasyfikacja to rodzaj algorytmu statystycznego, który przydziela obserwacje statystyczne do klas, bazując na atrybutach tych obserwacji.\n",
    "\n",
    "**Definicja:**\n",
    "Dla danego zbioru danych trenujących $\\{(x_1,y_1),\\ldots,(x_n,y_n)\\}$ algorytm potrafi znaleźć funkcję klasyfikującją $h: X -> Y$, która przydziela obiektowi $x\\in X$ klasę $y \\in Y$.\n",
    "\n",
    "- prawdopodobieństwo aposteriori: $P(Y=i|X)$ *\n",
    "- funkcja klasyfikacyjna przyjmuje postać: $h(X) = argmax_{1,\\ldots,y} P(Y=i|X)$\n",
    "\n",
    "*większość klasyfikatorów modeluje prawdopodobieństwa, wyjątek stanowi SVM\n",
    "\n",
    "Przykłady klasyfikacji:\n",
    "- wykrywanie czy pacjent jest chory na daną chorobę na podstawie wyników badań\n",
    "- klasyfikacja maili jako spam/nie-spam\n",
    "- czy transakcja dokonana na koncie klienta banku to oszustwo/kradzież czy też normalna transakcja\n",
    "- rozpoznawania na obrazu różnych rodzajów zwierząt\n",
    "- rozpoznawanie czy pasażer przeżyje katastrofę na Titanicu\n",
    "\n",
    "**Na potrzeby uproszczenia wyjaśniania w dalszej części labów, skupimy się tylko na klasyfikacji binarnej.**\n",
    "\n",
    "Zajmiemy się zbiorem gdzie klasyfikujemy u pacjentów czy występuje choroba serca czy nie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T15:01:18.130629Z",
     "start_time": "2020-03-07T15:01:18.127672Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T14:45:39.531710Z",
     "start_time": "2020-03-07T14:45:39.518696Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('heart.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T14:45:53.174538Z",
     "start_time": "2020-03-07T14:45:53.166435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Szybko sprawdzamy podstawowe cechy danych\n",
    "na_ratio_cols = data.isna().mean(axis=0)\n",
    "na_ratio_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data['chd'])\n",
    "X = data.drop(['chd','famhist'],axis=1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T14:52:23.920291Z",
     "start_time": "2020-03-07T14:52:23.911127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Szybkie ćwiczenie - wykonaj dowolne kodowanie zmiennej kategorycznej\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sposoby podziału danych\n",
    "- Jak radzić sobie z overfitingiem?\n",
    "- Jakie znacie sposoby podziału danych na treningowe i testowe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190523171258/overfitting_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/\n",
    "\n",
    "## Zbiór treningowy, walidacyjny i testowy¶\n",
    "Prosty podział danych na część, na której uczymy model i na część która służy nam do sprawdzenia jego skuteczności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T17:50:27.159896Z",
     "start_time": "2020-03-07T17:50:27.154910Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val, y_val, stratify=y_val, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_test).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T17:50:52.333567Z",
     "start_time": "2020-03-07T17:50:52.329929Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X.shape,X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaki znacie najprostszy klasyfikator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T16:35:17.078577Z",
     "start_time": "2020-03-07T16:35:17.072606Z"
    }
   },
   "outputs": [],
   "source": [
    "dc = DummyClassifier(strategy='uniform', random_state=42)\n",
    "dc.fit(X_train,y_train)\n",
    "y_proba = dc.predict_proba(X_val)\n",
    "y_hat = dc.predict(X_val)\n",
    "print(\"proba: \" + str(y_proba[0:10,0]) + '\\ny:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestujcie jaki będzie wynik działania algorytmu gdy zmienimy parametr *strategy* (oraz porównać accuracy) - podpowiedź: skorzystaj z dokumentacji funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: policzyć accuracy dla baselinu (z inną strategią niż uniform) na train i validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jakieś inne proste klasyfikatory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna - czemu by nie prognozować prawdopodobieństwa za pomocą regresji liniowej?\n",
    "\n",
    "**Przypomnienie:** uogólniony model liniowy: $y_{i}=\\beta _{0}1+\\beta _{1}x_{i1}+\\cdots +\\beta _{p}x_{ip} = x^T \\beta$\n",
    "\n",
    "- Jaki jest podstawowy problem z wykorzystaniem regresji do modelowania prawdopodobieństwa?\n",
    "- Jakie macie propozycje rozwiązania tego problemu?\n",
    "\n",
    "$odds = \\frac{P(Y=1|X)}{P(Y=0|X)} = \\frac{p}{1-p}$ $\\in (0,\\infty)$\n",
    "\n",
    "$\\log({odds}) \\in (-\\infty, \\infty)$\n",
    "\n",
    "Co pozwala nam modelować powyższe równanie dzięki regresji liniowej, po przekształceniu równania, uzyskujemy prawdopodobieństwo sukcesu:\n",
    "\n",
    "$x^T \\beta = \\log({\\frac{p}{1-p}}) \\Rightarrow p = \\frac{1}{1+\\exp({-x^T \\beta})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1534281070/linear_vs_logistic_regression_edxw03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T15:17:06.286476Z",
     "start_time": "2020-03-07T15:17:06.227772Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "y_hat = lr.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: policzyć accuracy dla logita z l1, l2, i bez regularyzacji na train i validation\n",
    "#porównać z baselinem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak interpretować wyniki?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jak się zmieni powyższy wynik gdy zwiększymy wartość czwartej cechy (tj. adiposity) dla pierwszej obserwacji o 1\n",
    "\n",
    "#solution\n",
    "experiment=X_val.iloc[0,:]\n",
    "experiment[3]=experiment[3]+1\n",
    "np.log(lr.predict_proba(experiment.values.reshape(1,-1))[0,1]/lr.predict_proba(experiment.values.reshape(1,-1))[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dlaczego można było się przewidzieć, że taki właśnie będzie wynik?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "np.log(lr.predict_proba(X_val)[0,1]/lr.predict_proba(X_val)[0,0])+lr.coef_[0,3]\n",
    "# otrzymano taki sam wynik - nie trzeba było wykonywać metody predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Jaki będzie wynik gdy wektor cech będzie miał tylko zerowe elementy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dlaczego można było się przewidzieć, że taki właśnie będzie wynik?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "1/(1+np.exp(-lr.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jakie są zalety regresji logistycznej?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drzewo decyzyjne\n",
    "- Jak wykorzystać model drzewa do predykcji klasyfikacji/regresji?\n",
    "- jakie problemy może to generować?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T16:33:36.468292Z",
     "start_time": "2020-03-07T16:33:36.240821Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier,plot_tree #export_graphviz\n",
    "## biblioteka poniżej może być problematyczna na Windows\n",
    "#import graphviz\n",
    "\n",
    "tree1 = DecisionTreeClassifier()\n",
    "\n",
    "tree1.fit(X_train,y_train)\n",
    "y_hat = tree1.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "\n",
    "#plt.figure(figsize=(20,20))\n",
    "#splits=tree.plot_tree(tree1, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO spróbujcie wytrenować model ze zmienionymi parametrami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "Znalezienie równania hiperpłaszczyzny, która najlepiej dzieli nasz zbiór danych na klasy.\n",
    "\n",
    "**Uwaga: w przypadku SVM nie modelujemy prawdopodobieństwa przynależności do danej klasy - domyślnym wyjściem jest informacja o konkretnej klasie**\n",
    "- Co jeżeli nie istnieje taka płaszczyzna?\n",
    "- Co jeżeli nasze dane nie są separowalne liniowo, tylko np. radialnie?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/300px-SVM_margin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Support-vector_machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://machine-learning-note.readthedocs.io/en/latest/_images/svm_kernel_trick.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machine-learning-note.readthedocs.io/en/latest/algorithm/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T16:57:59.319024Z",
     "start_time": "2020-03-07T16:57:59.302833Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "\n",
    "svm.fit(X_train,y_train)\n",
    "y_hat = svm.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jakie są wady?\n",
    "- trudno dobrać optymalne parametry\n",
    "- metoda wrażliwa na skalowanie danych\n",
    "- długo się \"uczy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiwny Klasyfikator Bayesowski\n",
    "Jest oparty na założeniu o wzajemnej niezależności zmiennych. Często nie mają one żadnego związku z rzeczywistością i właśnie z tego powodu nazywa się je naiwnymi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/cae70e6035d9ac52c547bc1c666e372063b85324)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mianownik nie zależy od C więc nie będziemy go dalej analizować - skupimy się na liczniku.\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/2d0555690cd428cb6d6a52ea6b6391256125a45c) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rekurencyjnie obliczenia będą kontynuowane. Teraz pora zrozumieć dokładniej dlaczego występuje słowo \"naiwny\" w nazwie metody.\n",
    "    Zakładamy bowiem że cechy $F_i$ są niezależne czyli ![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/8898f2ee081f407669fdb7a4f60e390615513346)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatecznie wzór to: ![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/a5978cc50b1c3d745ad304987a750aeb4a27df5b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pl.wikipedia.org/wiki/Naiwny_klasyfikator_bayesowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T17:27:54.549246Z",
     "start_time": "2020-03-07T17:27:54.541140Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_train,y_train)\n",
    "y_hat = nb.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lepszy sposób na podział danych na zbiory treningowe i testowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation\n",
    "- Czy możemy stosować CV dzieląc zbiór, tak by w zbiorze walidacyjnym pozostała tylko jedna obserwacja danych?\n",
    "- Czy sprawdzając performance modelu przez CV, możemy potem nauczyć model na całym zbiorze danych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T17:58:33.491733Z",
     "start_time": "2020-03-07T17:58:33.127377Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X_train_val=pd.concat((X_train,X_val))\n",
    "y_train_val=np.concatenate((y_train,y_val), axis=0)\n",
    "cross_val_score(lr, X_train_val, y_train_val, scoring='accuracy', cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miary ocen jakości klasyfikatorów\n",
    "- Jakie znacie miary oceny klasyfikatorów?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "$ACC = \\frac{TP+TN}{ALL}$\n",
    "\n",
    "Bardzo intuicyjna miara - ile obserwacji zakwalifikowaliśmy poprawnie.\n",
    "\n",
    "- Jaki jest problem z *accuracy*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & Recall\n",
    "$PRECISION = \\frac{TP}{TP+FP}= \\frac{TP}{\\text{TOTAL PREDICTED POSITIVE}}$\n",
    "\n",
    "$RECALL = \\frac{TP}{TP+FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score\n",
    "$F1\\_SCORE =\\frac{2*PRECISION*RECALL}{PRECISION+RECALL}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://mathspace.pl/wp-content/uploads/2016/09/ROC-krzywa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mathspace.pl/matematyka/receiver-operating-characteristic-krzywa-roc-czyli-ocena-jakosci-klasyfikacji-czesc-7/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/06/data-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie** - przetestować 3 modele przedstawione dziś na zajęciach i sprawdzić, który jest lepszy na podstawie wyżej wymienionych miar. Należy zastosować kroswalidację."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
